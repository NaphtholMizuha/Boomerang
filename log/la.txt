Files already downloaded and verified
Files already downloaded and verified
Round 1/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [0.06112486 0.06112486 0.06112486 0.06112486 0.06112486 0.06112486
 0.06112486 0.06112486 0.06112486 0.06112486]
hahaha
rev_score of L1: [0.05387684 0.05387684 0.05387684 0.05387684 0.05387684 0.05387684
 0.05387684 0.05387684 0.05387684 0.05387684]
rev_score of L2: [0.29112698 0.29112698 0.29112698 0.29112698 0.29112698 0.29112698
 0.29112698 0.29112698 0.29112698 0.29112698]
rev_score of L3: [0.31448481 0.31448481 0.31448481 0.31448481 0.31448481 0.31448481
 0.31448481 0.31448481 0.31448481 0.31448481]
rev_score of L4: [0.32104927 0.32104927 0.32104927 0.32104927 0.32104927 0.32104927
 0.32104927 0.32104927 0.32104927 0.32104927]
rev_score of L5: [0.29378666 0.29378666 0.29378666 0.29378666 0.29378666 0.29378666
 0.29378666 0.29378666 0.29378666 0.29378666]
rev_score of L6: [0.3172953 0.3172953 0.3172953 0.3172953 0.3172953 0.3172953 0.3172953
 0.3172953 0.3172953 0.3172953]
rev_score of L7: [0.29185893 0.29185893 0.29185893 0.29185893 0.29185893 0.29185893
 0.29185893 0.29185893 0.29185893 0.29185893]
rev_score of L8: [0.2571543 0.2571543 0.2571543 0.2571543 0.2571543 0.2571543 0.2571543
 0.2571543 0.2571543 0.2571543]
rev_score of L9: [0.30284213 0.30284213 0.30284213 0.30284213 0.30284213 0.30284213
 0.30284213 0.30284213 0.30284213 0.30284213]
rev_score of L10: [0.31079328 0.31079328 0.31079328 0.31079328 0.31079328 0.31079328
 0.31079328 0.31079328 0.31079328 0.31079328]
rev_score of L11: [0.32337904 0.32337904 0.32337904 0.32337904 0.32337904 0.32337904
 0.32337904 0.32337904 0.32337904 0.32337904]
rev_score of L12: [0.32281582 0.32281582 0.32281582 0.32281582 0.32281582 0.32281582
 0.32281582 0.32281582 0.32281582 0.32281582]
rev_score of L13: [0.30395315 0.30395315 0.30395315 0.30395315 0.30395315 0.30395315
 0.30395315 0.30395315 0.30395315 0.30395315]
rev_score of L14: [0.28655724 0.28655724 0.28655724 0.28655724 0.28655724 0.28655724
 0.28655724 0.28655724 0.28655724 0.28655724]
rev_score of L15: [0.28990328 0.28990328 0.28990328 0.28990328 0.28990328 0.28990328
 0.28990328 0.28990328 0.28990328 0.28990328]
rev_score of L16: [0.29669828 0.29669828 0.29669828 0.29669828 0.29669828 0.29669828
 0.29669828 0.29669828 0.29669828 0.29669828]
rev_score of L17: [0.27176108 0.27176108 0.27176108 0.27176108 0.27176108 0.27176108
 0.27176108 0.27176108 0.27176108 0.27176108]
rev_score of L18: [0.32989525 0.32989525 0.32989525 0.32989525 0.32989525 0.32989525
 0.32989525 0.32989525 0.32989525 0.32989525]
rev_score of L19: [0.2775566 0.2775566 0.2775566 0.2775566 0.2775566 0.2775566 0.2775566
 0.2775566 0.2775566 0.2775566]
fwd_score of A0: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A1: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A2: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A3: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A4: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A5: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A6: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A7: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A8: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A9: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Loss: 2.3056034683800353, Acc: 0.1
Round 2/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [0.22471257 0.22471257 0.22471257 0.22471257 0.22471257 0.22471257
 0.22471257 0.22471257 0.22471257 0.22471257]
hahaha
rev_score of L1: [0.21831802 0.21831802 0.21831802 0.21831802 0.21831802 0.21831802
 0.21831802 0.21831802 0.21831802 0.21831802]
rev_score of L2: [0.23552784 0.23552784 0.23552784 0.23552784 0.23552784 0.23552784
 0.23552784 0.23552784 0.23552784 0.23552784]
rev_score of L3: [0.22114927 0.22114927 0.22114927 0.22114927 0.22114927 0.22114927
 0.22114927 0.22114927 0.22114927 0.22114927]
rev_score of L4: [0.22193472 0.22193472 0.22193472 0.22193472 0.22193472 0.22193472
 0.22193472 0.22193472 0.22193472 0.22193472]
rev_score of L5: [0.21460422 0.21460422 0.21460422 0.21460422 0.21460422 0.21460422
 0.21460422 0.21460422 0.21460422 0.21460422]
rev_score of L6: [0.21714657 0.21714657 0.21714657 0.21714657 0.21714657 0.21714657
 0.21714657 0.21714657 0.21714657 0.21714657]
rev_score of L7: [0.218393 0.218393 0.218393 0.218393 0.218393 0.218393 0.218393 0.218393
 0.218393 0.218393]
rev_score of L8: [0.23953561 0.23953561 0.23953561 0.23953561 0.23953561 0.23953561
 0.23953561 0.23953561 0.23953561 0.23953561]
rev_score of L9: [0.21430304 0.21430304 0.21430304 0.21430304 0.21430304 0.21430304
 0.21430304 0.21430304 0.21430304 0.21430304]
rev_score of L10: [0.22021549 0.22021549 0.22021549 0.22021549 0.22021549 0.22021549
 0.22021549 0.22021549 0.22021549 0.22021549]
rev_score of L11: [0.2310489 0.2310489 0.2310489 0.2310489 0.2310489 0.2310489 0.2310489
 0.2310489 0.2310489 0.2310489]
rev_score of L12: [0.22730716 0.22730716 0.22730716 0.22730716 0.22730716 0.22730716
 0.22730716 0.22730716 0.22730716 0.22730716]
rev_score of L13: [0.23417738 0.23417738 0.23417738 0.23417738 0.23417738 0.23417738
 0.23417738 0.23417738 0.23417738 0.23417738]
rev_score of L14: [0.2367425 0.2367425 0.2367425 0.2367425 0.2367425 0.2367425 0.2367425
 0.2367425 0.2367425 0.2367425]
rev_score of L15: [0.22803393 0.22803393 0.22803393 0.22803393 0.22803393 0.22803393
 0.22803393 0.22803393 0.22803393 0.22803393]
rev_score of L16: [0.21468186 0.21468186 0.21468186 0.21468186 0.21468186 0.21468186
 0.21468186 0.21468186 0.21468186 0.21468186]
rev_score of L17: [0.23010348 0.23010348 0.23010348 0.23010348 0.23010348 0.23010348
 0.23010348 0.23010348 0.23010348 0.23010348]
rev_score of L18: [0.23438789 0.23438789 0.23438789 0.23438789 0.23438789 0.23438789
 0.23438789 0.23438789 0.23438789 0.23438789]
rev_score of L19: [0.2081018 0.2081018 0.2081018 0.2081018 0.2081018 0.2081018 0.2081018
 0.2081018 0.2081018 0.2081018]
fwd_score of A0: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A1: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A2: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A3: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A4: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A5: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A6: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A7: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A8: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
fwd_score of A9: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Loss: 2.3043800680020365, Acc: 0.1
Round 3/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [0.16332526 0.16332526 0.16332526 0.16332526 0.16332526 0.16332526
 0.16332526 0.16332526 0.16332526 0.16332526]
hahaha
rev_score of L1: [0.15237077 0.15237077 0.15237077 0.15237077 0.15237077 0.15237077
 0.15237077 0.15237077 0.15237077 0.15237077]
rev_score of L2: [0.25029542 0.25029542 0.25029542 0.25029542 0.25029542 0.25029542
 0.25029542 0.25029542 0.25029542 0.25029542]
rev_score of L3: [0.24777969 0.24777969 0.24777969 0.24777969 0.24777969 0.24777969
 0.24777969 0.24777969 0.24777969 0.24777969]
rev_score of L4: [0.25207936 0.25207936 0.25207936 0.25207936 0.25207936 0.25207936
 0.25207936 0.25207936 0.25207936 0.25207936]
rev_score of L5: [0.24653093 0.24653093 0.24653093 0.24653093 0.24653093 0.24653093
 0.24653093 0.24653093 0.24653093 0.24653093]
rev_score of L6: [0.2444898 0.2444898 0.2444898 0.2444898 0.2444898 0.2444898 0.2444898
 0.2444898 0.2444898 0.2444898]
rev_score of L7: [0.24257178 0.24257178 0.24257178 0.24257178 0.24257178 0.24257178
 0.24257178 0.24257178 0.24257178 0.24257178]
rev_score of L8: [0.25172083 0.25172083 0.25172083 0.25172083 0.25172083 0.25172083
 0.25172083 0.25172083 0.25172083 0.25172083]
rev_score of L9: [0.24738564 0.24738564 0.24738564 0.24738564 0.24738564 0.24738564
 0.24738564 0.24738564 0.24738564 0.24738564]
rev_score of L10: [0.24933882 0.24933882 0.24933882 0.24933882 0.24933882 0.24933882
 0.24933882 0.24933882 0.24933882 0.24933882]
rev_score of L11: [0.24792895 0.24792895 0.24792895 0.24792895 0.24792895 0.24792895
 0.24792895 0.24792895 0.24792895 0.24792895]
rev_score of L12: [0.23624119 0.23624119 0.23624119 0.23624119 0.23624119 0.23624119
 0.23624119 0.23624119 0.23624119 0.23624119]
rev_score of L13: [0.24573224 0.24573224 0.24573224 0.24573224 0.24573224 0.24573224
 0.24573224 0.24573224 0.24573224 0.24573224]
rev_score of L14: [0.24596909 0.24596909 0.24596909 0.24596909 0.24596909 0.24596909
 0.24596909 0.24596909 0.24596909 0.24596909]
rev_score of L15: [0.25414937 0.25414937 0.25414937 0.25414937 0.25414937 0.25414937
 0.25414937 0.25414937 0.25414937 0.25414937]
rev_score of L16: [0.24814974 0.24814974 0.24814974 0.24814974 0.24814974 0.24814974
 0.24814974 0.24814974 0.24814974 0.24814974]
rev_score of L17: [0.24914377 0.24914377 0.24914377 0.24914377 0.24914377 0.24914377
 0.24914377 0.24914377 0.24914377 0.24914377]
rev_score of L18: [0.24887734 0.24887734 0.24887734 0.24887734 0.24887734 0.24887734
 0.24887734 0.24887734 0.24887734 0.24887734]
rev_score of L19: [0.23660187 0.23660187 0.23660187 0.23660187 0.23660187 0.23660187
 0.23660187 0.23660187 0.23660187 0.23660187]
fwd_score of A0: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A1: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A2: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A3: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A4: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A5: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A6: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A7: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A8: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A9: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Loss: 2.3040072476140225, Acc: 0.1
Round 4/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.07620016 -0.07620016 -0.07620016 -0.07620016 -0.07620016 -0.07620016
 -0.07620016 -0.07620016 -0.07620016 -0.07620016]
hahaha
rev_score of L1: [-0.09457154 -0.09457154 -0.09457154 -0.09457154 -0.09457154 -0.09457154
 -0.09457154 -0.09457154 -0.09457154 -0.09457154]
rev_score of L2: [0.21221738 0.21221738 0.21221738 0.21221738 0.21221738 0.21221738
 0.21221738 0.21221738 0.21221738 0.21221738]
rev_score of L3: [0.20906292 0.20906292 0.20906292 0.20906292 0.20906292 0.20906292
 0.20906292 0.20906292 0.20906292 0.20906292]
rev_score of L4: [0.21685635 0.21685635 0.21685635 0.21685635 0.21685635 0.21685635
 0.21685635 0.21685635 0.21685635 0.21685635]
rev_score of L5: [0.214614 0.214614 0.214614 0.214614 0.214614 0.214614 0.214614 0.214614
 0.214614 0.214614]
rev_score of L6: [0.2054364 0.2054364 0.2054364 0.2054364 0.2054364 0.2054364 0.2054364
 0.2054364 0.2054364 0.2054364]
rev_score of L7: [0.20817794 0.20817794 0.20817794 0.20817794 0.20817794 0.20817794
 0.20817794 0.20817794 0.20817794 0.20817794]
rev_score of L8: [0.19604038 0.19604038 0.19604038 0.19604038 0.19604038 0.19604038
 0.19604038 0.19604038 0.19604038 0.19604038]
rev_score of L9: [0.21512631 0.21512631 0.21512631 0.21512631 0.21512631 0.21512631
 0.21512631 0.21512631 0.21512631 0.21512631]
rev_score of L10: [0.22680851 0.22680851 0.22680851 0.22680851 0.22680851 0.22680851
 0.22680851 0.22680851 0.22680851 0.22680851]
rev_score of L11: [0.22389931 0.22389931 0.22389931 0.22389931 0.22389931 0.22389931
 0.22389931 0.22389931 0.22389931 0.22389931]
rev_score of L12: [0.21791883 0.21791883 0.21791883 0.21791883 0.21791883 0.21791883
 0.21791883 0.21791883 0.21791883 0.21791883]
rev_score of L13: [0.2204844 0.2204844 0.2204844 0.2204844 0.2204844 0.2204844 0.2204844
 0.2204844 0.2204844 0.2204844]
rev_score of L14: [0.09801069 0.09801069 0.09801069 0.09801069 0.09801069 0.09801069
 0.09801069 0.09801069 0.09801069 0.09801069]
rev_score of L15: [0.18690983 0.18690983 0.18690983 0.18690983 0.18690983 0.18690983
 0.18690983 0.18690983 0.18690983 0.18690983]
rev_score of L16: [0.24080645 0.24080645 0.24080645 0.24080645 0.24080645 0.24080645
 0.24080645 0.24080645 0.24080645 0.24080645]
rev_score of L17: [0.21848044 0.21848044 0.21848044 0.21848044 0.21848044 0.21848044
 0.21848044 0.21848044 0.21848044 0.21848044]
rev_score of L18: [0.21161802 0.21161802 0.21161802 0.21161802 0.21161802 0.21161802
 0.21161802 0.21161802 0.21161802 0.21161802]
rev_score of L19: [0.22168829 0.22168829 0.22168829 0.22168829 0.22168829 0.22168829
 0.22168829 0.22168829 0.22168829 0.22168829]
fwd_score of A0: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A1: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A2: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A3: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A4: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A5: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A6: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A7: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A8: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
fwd_score of A9: [1.  0.8 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
 1.  1. ]
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Loss: 2.268767741541512, Acc: 0.1112
Round 5/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.41783917 -0.41783917 -0.41783917 -0.41783917 -0.41783917 -0.41783917
 -0.41783917 -0.41783917 -0.41783917 -0.41783917]
hahaha
rev_score of L1: [-0.44343993 -0.44343993 -0.44343993 -0.44343993 -0.44343993 -0.44343993
 -0.44343993 -0.44343993 -0.44343993 -0.44343993]
rev_score of L2: [0.28183848 0.28183848 0.28183848 0.28183848 0.28183848 0.28183848
 0.28183848 0.28183848 0.28183848 0.28183848]
rev_score of L3: [0.28531908 0.28531908 0.28531908 0.28531908 0.28531908 0.28531908
 0.28531908 0.28531908 0.28531908 0.28531908]
rev_score of L4: [0.29420835 0.29420835 0.29420835 0.29420835 0.29420835 0.29420835
 0.29420835 0.29420835 0.29420835 0.29420835]
rev_score of L5: [0.27642795 0.27642795 0.27642795 0.27642795 0.27642795 0.27642795
 0.27642795 0.27642795 0.27642795 0.27642795]
rev_score of L6: [0.26833856 0.26833856 0.26833856 0.26833856 0.26833856 0.26833856
 0.26833856 0.26833856 0.26833856 0.26833856]
rev_score of L7: [0.30042552 0.30042552 0.30042552 0.30042552 0.30042552 0.30042552
 0.30042552 0.30042552 0.30042552 0.30042552]
rev_score of L8: [0.29262317 0.29262317 0.29262317 0.29262317 0.29262317 0.29262317
 0.29262317 0.29262317 0.29262317 0.29262317]
rev_score of L9: [0.27681996 0.27681996 0.27681996 0.27681996 0.27681996 0.27681996
 0.27681996 0.27681996 0.27681996 0.27681996]
rev_score of L10: [0.30342331 0.30342331 0.30342331 0.30342331 0.30342331 0.30342331
 0.30342331 0.30342331 0.30342331 0.30342331]
rev_score of L11: [0.30889254 0.30889254 0.30889254 0.30889254 0.30889254 0.30889254
 0.30889254 0.30889254 0.30889254 0.30889254]
rev_score of L12: [0.29132314 0.29132314 0.29132314 0.29132314 0.29132314 0.29132314
 0.29132314 0.29132314 0.29132314 0.29132314]
rev_score of L13: [0.29530032 0.29530032 0.29530032 0.29530032 0.29530032 0.29530032
 0.29530032 0.29530032 0.29530032 0.29530032]
rev_score of L14: [0.28171116 0.28171116 0.28171116 0.28171116 0.28171116 0.28171116
 0.28171116 0.28171116 0.28171116 0.28171116]
rev_score of L15: [0.27542969 0.27542969 0.27542969 0.27542969 0.27542969 0.27542969
 0.27542969 0.27542969 0.27542969 0.27542969]
rev_score of L16: [0.27990732 0.27990732 0.27990732 0.27990732 0.27990732 0.27990732
 0.27990732 0.27990732 0.27990732 0.27990732]
rev_score of L17: [0.28536235 0.28536235 0.28536235 0.28536235 0.28536235 0.28536235
 0.28536235 0.28536235 0.28536235 0.28536235]
rev_score of L18: [0.29972511 0.29972511 0.29972511 0.29972511 0.29972511 0.29972511
 0.29972511 0.29972511 0.29972511 0.29972511]
rev_score of L19: [0.31100513 0.31100513 0.31100513 0.31100513 0.31100513 0.31100513
 0.31100513 0.31100513 0.31100513 0.31100513]
fwd_score of A0: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A1: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A2: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A3: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A4: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A5: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A6: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A7: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A8: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A9: [1.   0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Loss: 2.3009464969269384, Acc: 0.1033
Round 6/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.50938752 -0.50938752 -0.50938752 -0.50938752 -0.50938752 -0.50938752
 -0.50938752 -0.50938752 -0.50938752 -0.50938752]
hahaha
rev_score of L1: [-0.50181964 -0.50181964 -0.50181964 -0.50181964 -0.50181964 -0.50181964
 -0.50181964 -0.50181964 -0.50181964 -0.50181964]
rev_score of L2: [0.30737342 0.30737342 0.30737342 0.30737342 0.30737342 0.30737342
 0.30737342 0.30737342 0.30737342 0.30737342]
rev_score of L3: [0.29684894 0.29684894 0.29684894 0.29684894 0.29684894 0.29684894
 0.29684894 0.29684894 0.29684894 0.29684894]
rev_score of L4: [0.31746758 0.31746758 0.31746758 0.31746758 0.31746758 0.31746758
 0.31746758 0.31746758 0.31746758 0.31746758]
rev_score of L5: [0.29499102 0.29499102 0.29499102 0.29499102 0.29499102 0.29499102
 0.29499102 0.29499102 0.29499102 0.29499102]
rev_score of L6: [0.3089113 0.3089113 0.3089113 0.3089113 0.3089113 0.3089113 0.3089113
 0.3089113 0.3089113 0.3089113]
rev_score of L7: [0.30501197 0.30501197 0.30501197 0.30501197 0.30501197 0.30501197
 0.30501197 0.30501197 0.30501197 0.30501197]
rev_score of L8: [0.31277352 0.31277352 0.31277352 0.31277352 0.31277352 0.31277352
 0.31277352 0.31277352 0.31277352 0.31277352]
rev_score of L9: [0.30616686 0.30616686 0.30616686 0.30616686 0.30616686 0.30616686
 0.30616686 0.30616686 0.30616686 0.30616686]
rev_score of L10: [0.28922381 0.28922381 0.28922381 0.28922381 0.28922381 0.28922381
 0.28922381 0.28922381 0.28922381 0.28922381]
rev_score of L11: [0.2920808 0.2920808 0.2920808 0.2920808 0.2920808 0.2920808 0.2920808
 0.2920808 0.2920808 0.2920808]
rev_score of L12: [0.30910936 0.30910936 0.30910936 0.30910936 0.30910936 0.30910936
 0.30910936 0.30910936 0.30910936 0.30910936]
rev_score of L13: [0.31008665 0.31008665 0.31008665 0.31008665 0.31008665 0.31008665
 0.31008665 0.31008665 0.31008665 0.31008665]
rev_score of L14: [0.26316153 0.26316153 0.26316153 0.26316153 0.26316153 0.26316153
 0.26316153 0.26316153 0.26316153 0.26316153]
rev_score of L15: [0.27943526 0.27943526 0.27943526 0.27943526 0.27943526 0.27943526
 0.27943526 0.27943526 0.27943526 0.27943526]
rev_score of L16: [0.28771784 0.28771784 0.28771784 0.28771784 0.28771784 0.28771784
 0.28771784 0.28771784 0.28771784 0.28771784]
rev_score of L17: [0.30261599 0.30261599 0.30261599 0.30261599 0.30261599 0.30261599
 0.30261599 0.30261599 0.30261599 0.30261599]
rev_score of L18: [0.29572598 0.29572598 0.29572598 0.29572598 0.29572598 0.29572598
 0.29572598 0.29572598 0.29572598 0.29572598]
rev_score of L19: [0.31975042 0.31975042 0.31975042 0.31975042 0.31975042 0.31975042
 0.31975042 0.31975042 0.31975042 0.31975042]
fwd_score of A0: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A1: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A2: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A3: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A4: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A5: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A6: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A7: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A8: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A9: [0.8  0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Loss: 2.306721548683727, Acc: 0.1
Round 7/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.36451052 -0.36451052 -0.36451052 -0.36451052 -0.36451052 -0.36451052
 -0.36451052 -0.36451052 -0.36451052 -0.36451052]
hahaha
rev_score of L1: [-0.34540003 -0.34540003 -0.34540003 -0.34540003 -0.34540003 -0.34540003
 -0.34540003 -0.34540003 -0.34540003 -0.34540003]
rev_score of L2: [0.27299364 0.27299364 0.27299364 0.27299364 0.27299364 0.27299364
 0.27299364 0.27299364 0.27299364 0.27299364]
rev_score of L3: [0.2772286 0.2772286 0.2772286 0.2772286 0.2772286 0.2772286 0.2772286
 0.2772286 0.2772286 0.2772286]
rev_score of L4: [0.31302244 0.31302244 0.31302244 0.31302244 0.31302244 0.31302244
 0.31302244 0.31302244 0.31302244 0.31302244]
rev_score of L5: [0.28037504 0.28037504 0.28037504 0.28037504 0.28037504 0.28037504
 0.28037504 0.28037504 0.28037504 0.28037504]
rev_score of L6: [0.29576154 0.29576154 0.29576154 0.29576154 0.29576154 0.29576154
 0.29576154 0.29576154 0.29576154 0.29576154]
rev_score of L7: [0.2858199 0.2858199 0.2858199 0.2858199 0.2858199 0.2858199 0.2858199
 0.2858199 0.2858199 0.2858199]
rev_score of L8: [0.28012842 0.28012842 0.28012842 0.28012842 0.28012842 0.28012842
 0.28012842 0.28012842 0.28012842 0.28012842]
rev_score of L9: [0.269472 0.269472 0.269472 0.269472 0.269472 0.269472 0.269472 0.269472
 0.269472 0.269472]
rev_score of L10: [0.25912308 0.25912308 0.25912308 0.25912308 0.25912308 0.25912308
 0.25912308 0.25912308 0.25912308 0.25912308]
rev_score of L11: [0.27512779 0.27512779 0.27512779 0.27512779 0.27512779 0.27512779
 0.27512779 0.27512779 0.27512779 0.27512779]
rev_score of L12: [0.26660334 0.26660334 0.26660334 0.26660334 0.26660334 0.26660334
 0.26660334 0.26660334 0.26660334 0.26660334]
rev_score of L13: [0.30532172 0.30532172 0.30532172 0.30532172 0.30532172 0.30532172
 0.30532172 0.30532172 0.30532172 0.30532172]
rev_score of L14: [0.28134307 0.28134307 0.28134307 0.28134307 0.28134307 0.28134307
 0.28134307 0.28134307 0.28134307 0.28134307]
rev_score of L15: [0.28523271 0.28523271 0.28523271 0.28523271 0.28523271 0.28523271
 0.28523271 0.28523271 0.28523271 0.28523271]
rev_score of L16: [0.2555776 0.2555776 0.2555776 0.2555776 0.2555776 0.2555776 0.2555776
 0.2555776 0.2555776 0.2555776]
rev_score of L17: [0.27935295 0.27935295 0.27935295 0.27935295 0.27935295 0.27935295
 0.27935295 0.27935295 0.27935295 0.27935295]
rev_score of L18: [0.25563384 0.25563384 0.25563384 0.25563384 0.25563384 0.25563384
 0.25563384 0.25563384 0.25563384 0.25563384]
rev_score of L19: [0.27633794 0.27633794 0.27633794 0.27633794 0.27633794 0.27633794
 0.27633794 0.27633794 0.27633794 0.27633794]
fwd_score of A0: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A1: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A2: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A3: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A4: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A5: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A6: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A7: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A8: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
fwd_score of A9: [0.64 0.64 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.
 1.   1.   1.   1.   1.   1.  ]
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Loss: 2.3232300570978524, Acc: 0.0727
Round 8/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.28855564 -0.28855564 -0.28855564 -0.28855564 -0.28855564 -0.28855564
 -0.28855564 -0.28855564 -0.28855564 -0.28855564]
hahaha
rev_score of L1: [-0.28171374 -0.28171374 -0.28171374 -0.28171374 -0.28171374 -0.28171374
 -0.28171374 -0.28171374 -0.28171374 -0.28171374]
rev_score of L2: [0.37346856 0.37346856 0.37346856 0.37346856 0.37346856 0.37346856
 0.37346856 0.37346856 0.37346856 0.37346856]
rev_score of L3: [0.40092571 0.40092571 0.40092571 0.40092571 0.40092571 0.40092571
 0.40092571 0.40092571 0.40092571 0.40092571]
rev_score of L4: [0.4113753 0.4113753 0.4113753 0.4113753 0.4113753 0.4113753 0.4113753
 0.4113753 0.4113753 0.4113753]
rev_score of L5: [0.40309095 0.40309095 0.40309095 0.40309095 0.40309095 0.40309095
 0.40309095 0.40309095 0.40309095 0.40309095]
rev_score of L6: [0.41126172 0.41126172 0.41126172 0.41126172 0.41126172 0.41126172
 0.41126172 0.41126172 0.41126172 0.41126172]
rev_score of L7: [0.32799317 0.32799317 0.32799317 0.32799317 0.32799317 0.32799317
 0.32799317 0.32799317 0.32799317 0.32799317]
rev_score of L8: [0.40544621 0.40544621 0.40544621 0.40544621 0.40544621 0.40544621
 0.40544621 0.40544621 0.40544621 0.40544621]
rev_score of L9: [0.39336403 0.39336403 0.39336403 0.39336403 0.39336403 0.39336403
 0.39336403 0.39336403 0.39336403 0.39336403]
rev_score of L10: [0.40217848 0.40217848 0.40217848 0.40217848 0.40217848 0.40217848
 0.40217848 0.40217848 0.40217848 0.40217848]
rev_score of L11: [0.40831683 0.40831683 0.40831683 0.40831683 0.40831683 0.40831683
 0.40831683 0.40831683 0.40831683 0.40831683]
rev_score of L12: [0.37746792 0.37746792 0.37746792 0.37746792 0.37746792 0.37746792
 0.37746792 0.37746792 0.37746792 0.37746792]
rev_score of L13: [0.38576588 0.38576588 0.38576588 0.38576588 0.38576588 0.38576588
 0.38576588 0.38576588 0.38576588 0.38576588]
rev_score of L14: [0.40644313 0.40644313 0.40644313 0.40644313 0.40644313 0.40644313
 0.40644313 0.40644313 0.40644313 0.40644313]
rev_score of L15: [0.41889002 0.41889002 0.41889002 0.41889002 0.41889002 0.41889002
 0.41889002 0.41889002 0.41889002 0.41889002]
rev_score of L16: [0.40133148 0.40133148 0.40133148 0.40133148 0.40133148 0.40133148
 0.40133148 0.40133148 0.40133148 0.40133148]
rev_score of L17: [0.39493214 0.39493214 0.39493214 0.39493214 0.39493214 0.39493214
 0.39493214 0.39493214 0.39493214 0.39493214]
rev_score of L18: [0.38773894 0.38773894 0.38773894 0.38773894 0.38773894 0.38773894
 0.38773894 0.38773894 0.38773894 0.38773894]
rev_score of L19: [0.40998103 0.40998103 0.40998103 0.40998103 0.40998103 0.40998103
 0.40998103 0.40998103 0.40998103 0.40998103]
fwd_score of A0: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A1: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A2: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A3: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A4: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A5: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A6: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A7: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A8: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
fwd_score of A9: [0.512 0.64  1.    1.    1.    1.    1.    1.    1.    1.    1.    1.
 1.    1.    1.    1.    1.    1.    1.    1.   ]
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Loss: 2.168302636938735, Acc: 0.1485
Round 9/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.09046245 -0.09046245 -0.09046245 -0.09046245 -0.09046245 -0.09046245
 -0.09046245 -0.09046245 -0.09046245 -0.09046245]
hahaha
rev_score of L1: [-0.08441095 -0.08441095 -0.08441095 -0.08441095 -0.08441095 -0.08441095
 -0.08441095 -0.08441095 -0.08441095 -0.08441095]
rev_score of L2: [0.31355922 0.31355922 0.31355922 0.31355922 0.31355922 0.31355922
 0.31355922 0.31355922 0.31355922 0.31355922]
rev_score of L3: [0.31015376 0.31015376 0.31015376 0.31015376 0.31015376 0.31015376
 0.31015376 0.31015376 0.31015376 0.31015376]
rev_score of L4: [0.29988161 0.29988161 0.29988161 0.29988161 0.29988161 0.29988161
 0.29988161 0.29988161 0.29988161 0.29988161]
rev_score of L5: [0.30148339 0.30148339 0.30148339 0.30148339 0.30148339 0.30148339
 0.30148339 0.30148339 0.30148339 0.30148339]
rev_score of L6: [0.30393041 0.30393041 0.30393041 0.30393041 0.30393041 0.30393041
 0.30393041 0.30393041 0.30393041 0.30393041]
rev_score of L7: [0.28911615 0.28911615 0.28911615 0.28911615 0.28911615 0.28911615
 0.28911615 0.28911615 0.28911615 0.28911615]
rev_score of L8: [0.29289384 0.29289384 0.29289384 0.29289384 0.29289384 0.29289384
 0.29289384 0.29289384 0.29289384 0.29289384]
rev_score of L9: [0.27517655 0.27517655 0.27517655 0.27517655 0.27517655 0.27517655
 0.27517655 0.27517655 0.27517655 0.27517655]
rev_score of L10: [0.3094603 0.3094603 0.3094603 0.3094603 0.3094603 0.3094603 0.3094603
 0.3094603 0.3094603 0.3094603]
rev_score of L11: [0.29164796 0.29164796 0.29164796 0.29164796 0.29164796 0.29164796
 0.29164796 0.29164796 0.29164796 0.29164796]
rev_score of L12: [0.31228473 0.31228473 0.31228473 0.31228473 0.31228473 0.31228473
 0.31228473 0.31228473 0.31228473 0.31228473]
rev_score of L13: [0.30866141 0.30866141 0.30866141 0.30866141 0.30866141 0.30866141
 0.30866141 0.30866141 0.30866141 0.30866141]
rev_score of L14: [0.31175887 0.31175887 0.31175887 0.31175887 0.31175887 0.31175887
 0.31175887 0.31175887 0.31175887 0.31175887]
rev_score of L15: [0.30853911 0.30853911 0.30853911 0.30853911 0.30853911 0.30853911
 0.30853911 0.30853911 0.30853911 0.30853911]
rev_score of L16: [0.304292 0.304292 0.304292 0.304292 0.304292 0.304292 0.304292 0.304292
 0.304292 0.304292]
rev_score of L17: [0.31586687 0.31586687 0.31586687 0.31586687 0.31586687 0.31586687
 0.31586687 0.31586687 0.31586687 0.31586687]
rev_score of L18: [0.29091996 0.29091996 0.29091996 0.29091996 0.29091996 0.29091996
 0.29091996 0.29091996 0.29091996 0.29091996]
rev_score of L19: [0.30423175 0.30423175 0.30423175 0.30423175 0.30423175 0.30423175
 0.30423175 0.30423175 0.30423175 0.30423175]
fwd_score of A0: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A1: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A2: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A3: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A4: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A5: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A6: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A7: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A8: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A9: [0.4096 0.64   1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Loss: 2.2783098700709234, Acc: 0.1336
Round 10/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.1039554 -0.1039554 -0.1039554 -0.1039554 -0.1039554 -0.1039554
 -0.1039554 -0.1039554 -0.1039554 -0.1039554]
hahaha
rev_score of L1: [-0.1120928 -0.1120928 -0.1120928 -0.1120928 -0.1120928 -0.1120928
 -0.1120928 -0.1120928 -0.1120928 -0.1120928]
rev_score of L2: [0.28137105 0.28137105 0.28137105 0.28137105 0.28137105 0.28137105
 0.28137105 0.28137105 0.28137105 0.28137105]
rev_score of L3: [0.25322318 0.25322318 0.25322318 0.25322318 0.25322318 0.25322318
 0.25322318 0.25322318 0.25322318 0.25322318]
rev_score of L4: [0.27400831 0.27400831 0.27400831 0.27400831 0.27400831 0.27400831
 0.27400831 0.27400831 0.27400831 0.27400831]
rev_score of L5: [0.28155986 0.28155986 0.28155986 0.28155986 0.28155986 0.28155986
 0.28155986 0.28155986 0.28155986 0.28155986]
rev_score of L6: [0.28608625 0.28608625 0.28608625 0.28608625 0.28608625 0.28608625
 0.28608625 0.28608625 0.28608625 0.28608625]
rev_score of L7: [0.27091096 0.27091096 0.27091096 0.27091096 0.27091096 0.27091096
 0.27091096 0.27091096 0.27091096 0.27091096]
rev_score of L8: [0.26673539 0.26673539 0.26673539 0.26673539 0.26673539 0.26673539
 0.26673539 0.26673539 0.26673539 0.26673539]
rev_score of L9: [0.26221114 0.26221114 0.26221114 0.26221114 0.26221114 0.26221114
 0.26221114 0.26221114 0.26221114 0.26221114]
rev_score of L10: [0.29273757 0.29273757 0.29273757 0.29273757 0.29273757 0.29273757
 0.29273757 0.29273757 0.29273757 0.29273757]
rev_score of L11: [0.26960694 0.26960694 0.26960694 0.26960694 0.26960694 0.26960694
 0.26960694 0.26960694 0.26960694 0.26960694]
rev_score of L12: [0.27463762 0.27463762 0.27463762 0.27463762 0.27463762 0.27463762
 0.27463762 0.27463762 0.27463762 0.27463762]
rev_score of L13: [0.28267791 0.28267791 0.28267791 0.28267791 0.28267791 0.28267791
 0.28267791 0.28267791 0.28267791 0.28267791]
rev_score of L14: [0.26980212 0.26980212 0.26980212 0.26980212 0.26980212 0.26980212
 0.26980212 0.26980212 0.26980212 0.26980212]
rev_score of L15: [0.27109727 0.27109727 0.27109727 0.27109727 0.27109727 0.27109727
 0.27109727 0.27109727 0.27109727 0.27109727]
rev_score of L16: [0.27125317 0.27125317 0.27125317 0.27125317 0.27125317 0.27125317
 0.27125317 0.27125317 0.27125317 0.27125317]
rev_score of L17: [0.28232328 0.28232328 0.28232328 0.28232328 0.28232328 0.28232328
 0.28232328 0.28232328 0.28232328 0.28232328]
rev_score of L18: [0.25514361 0.25514361 0.25514361 0.25514361 0.25514361 0.25514361
 0.25514361 0.25514361 0.25514361 0.25514361]
rev_score of L19: [0.28230986 0.28230986 0.28230986 0.28230986 0.28230986 0.28230986
 0.28230986 0.28230986 0.28230986 0.28230986]
fwd_score of A0: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A1: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A2: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A3: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A4: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A5: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A6: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A7: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A8: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A9: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Loss: 2.3132212938972936, Acc: 0.0992
Round 11/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.3788024 -0.3788024 -0.3788024 -0.3788024 -0.3788024 -0.3788024
 -0.3788024 -0.3788024 -0.3788024 -0.3788024]
hahaha
rev_score of L1: [-0.37636068 -0.37636068 -0.37636068 -0.37636068 -0.37636068 -0.37636068
 -0.37636068 -0.37636068 -0.37636068 -0.37636068]
rev_score of L2: [0.41925114 0.41925114 0.41925114 0.41925114 0.41925114 0.41925114
 0.41925114 0.41925114 0.41925114 0.41925114]
rev_score of L3: [0.40080282 0.40080282 0.40080282 0.40080282 0.40080282 0.40080282
 0.40080282 0.40080282 0.40080282 0.40080282]
rev_score of L4: [0.40231638 0.40231638 0.40231638 0.40231638 0.40231638 0.40231638
 0.40231638 0.40231638 0.40231638 0.40231638]
rev_score of L5: [0.40673801 0.40673801 0.40673801 0.40673801 0.40673801 0.40673801
 0.40673801 0.40673801 0.40673801 0.40673801]
rev_score of L6: [0.41050087 0.41050087 0.41050087 0.41050087 0.41050087 0.41050087
 0.41050087 0.41050087 0.41050087 0.41050087]
rev_score of L7: [0.44887721 0.44887721 0.44887721 0.44887721 0.44887721 0.44887721
 0.44887721 0.44887721 0.44887721 0.44887721]
rev_score of L8: [0.3965104 0.3965104 0.3965104 0.3965104 0.3965104 0.3965104 0.3965104
 0.3965104 0.3965104 0.3965104]
rev_score of L9: [0.41637195 0.41637195 0.41637195 0.41637195 0.41637195 0.41637195
 0.41637195 0.41637195 0.41637195 0.41637195]
rev_score of L10: [0.43786528 0.43786528 0.43786528 0.43786528 0.43786528 0.43786528
 0.43786528 0.43786528 0.43786528 0.43786528]
rev_score of L11: [0.44024258 0.44024258 0.44024258 0.44024258 0.44024258 0.44024258
 0.44024258 0.44024258 0.44024258 0.44024258]
rev_score of L12: [0.45000369 0.45000369 0.45000369 0.45000369 0.45000369 0.45000369
 0.45000369 0.45000369 0.45000369 0.45000369]
rev_score of L13: [0.41771831 0.41771831 0.41771831 0.41771831 0.41771831 0.41771831
 0.41771831 0.41771831 0.41771831 0.41771831]
rev_score of L14: [0.43589003 0.43589003 0.43589003 0.43589003 0.43589003 0.43589003
 0.43589003 0.43589003 0.43589003 0.43589003]
rev_score of L15: [0.41518734 0.41518734 0.41518734 0.41518734 0.41518734 0.41518734
 0.41518734 0.41518734 0.41518734 0.41518734]
rev_score of L16: [0.39267954 0.39267954 0.39267954 0.39267954 0.39267954 0.39267954
 0.39267954 0.39267954 0.39267954 0.39267954]
rev_score of L17: [0.41849186 0.41849186 0.41849186 0.41849186 0.41849186 0.41849186
 0.41849186 0.41849186 0.41849186 0.41849186]
rev_score of L18: [0.42679931 0.42679931 0.42679931 0.42679931 0.42679931 0.42679931
 0.42679931 0.42679931 0.42679931 0.42679931]
rev_score of L19: [0.4238491 0.4238491 0.4238491 0.4238491 0.4238491 0.4238491 0.4238491
 0.4238491 0.4238491 0.4238491]
fwd_score of A0: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A1: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A2: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A3: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A4: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A5: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A6: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A7: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A8: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A9: [0.4096 0.512  1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Loss: 2.4209010006901557, Acc: 0.1015
Round 12/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4321913 -0.4321913 -0.4321913 -0.4321913 -0.4321913 -0.4321913
 -0.4321913 -0.4321913 -0.4321913 -0.4321913]
hahaha
rev_score of L1: [-0.44006719 -0.44006719 -0.44006719 -0.44006719 -0.44006719 -0.44006719
 -0.44006719 -0.44006719 -0.44006719 -0.44006719]
rev_score of L2: [0.43078788 0.43078788 0.43078788 0.43078788 0.43078788 0.43078788
 0.43078788 0.43078788 0.43078788 0.43078788]
rev_score of L3: [0.41124048 0.41124048 0.41124048 0.41124048 0.41124048 0.41124048
 0.41124048 0.41124048 0.41124048 0.41124048]
rev_score of L4: [0.42767785 0.42767785 0.42767785 0.42767785 0.42767785 0.42767785
 0.42767785 0.42767785 0.42767785 0.42767785]
rev_score of L5: [0.4241854 0.4241854 0.4241854 0.4241854 0.4241854 0.4241854 0.4241854
 0.4241854 0.4241854 0.4241854]
rev_score of L6: [0.42281783 0.42281783 0.42281783 0.42281783 0.42281783 0.42281783
 0.42281783 0.42281783 0.42281783 0.42281783]
rev_score of L7: [0.43128738 0.43128738 0.43128738 0.43128738 0.43128738 0.43128738
 0.43128738 0.43128738 0.43128738 0.43128738]
rev_score of L8: [0.41604334 0.41604334 0.41604334 0.41604334 0.41604334 0.41604334
 0.41604334 0.41604334 0.41604334 0.41604334]
rev_score of L9: [0.4328847 0.4328847 0.4328847 0.4328847 0.4328847 0.4328847 0.4328847
 0.4328847 0.4328847 0.4328847]
rev_score of L10: [0.42360934 0.42360934 0.42360934 0.42360934 0.42360934 0.42360934
 0.42360934 0.42360934 0.42360934 0.42360934]
rev_score of L11: [0.43663074 0.43663074 0.43663074 0.43663074 0.43663074 0.43663074
 0.43663074 0.43663074 0.43663074 0.43663074]
rev_score of L12: [0.4244208 0.4244208 0.4244208 0.4244208 0.4244208 0.4244208 0.4244208
 0.4244208 0.4244208 0.4244208]
rev_score of L13: [0.42536374 0.42536374 0.42536374 0.42536374 0.42536374 0.42536374
 0.42536374 0.42536374 0.42536374 0.42536374]
rev_score of L14: [0.40628771 0.40628771 0.40628771 0.40628771 0.40628771 0.40628771
 0.40628771 0.40628771 0.40628771 0.40628771]
rev_score of L15: [0.42889351 0.42889351 0.42889351 0.42889351 0.42889351 0.42889351
 0.42889351 0.42889351 0.42889351 0.42889351]
rev_score of L16: [0.4261871 0.4261871 0.4261871 0.4261871 0.4261871 0.4261871 0.4261871
 0.4261871 0.4261871 0.4261871]
rev_score of L17: [0.42812773 0.42812773 0.42812773 0.42812773 0.42812773 0.42812773
 0.42812773 0.42812773 0.42812773 0.42812773]
rev_score of L18: [0.42375058 0.42375058 0.42375058 0.42375058 0.42375058 0.42375058
 0.42375058 0.42375058 0.42375058 0.42375058]
rev_score of L19: [0.4219411 0.4219411 0.4219411 0.4219411 0.4219411 0.4219411 0.4219411
 0.4219411 0.4219411 0.4219411]
fwd_score of A0: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A1: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A2: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A3: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A4: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A5: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A6: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A7: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A8: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
fwd_score of A9: [0.4096 0.4096 1.     1.     1.     1.     1.     1.     1.     1.
 1.     1.     1.     1.     1.     1.     1.     1.     1.     1.    ]
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Loss: 2.1445467959577664, Acc: 0.1634
Round 13/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.37763611 -0.37763611 -0.37763611 -0.37763611 -0.37763611 -0.37763611
 -0.37763611 -0.37763611 -0.37763611 -0.37763611]
hahaha
rev_score of L1: [-0.39084608 -0.39084608 -0.39084608 -0.39084608 -0.39084608 -0.39084608
 -0.39084608 -0.39084608 -0.39084608 -0.39084608]
rev_score of L2: [0.38535039 0.38535039 0.38535039 0.38535039 0.38535039 0.38535039
 0.38535039 0.38535039 0.38535039 0.38535039]
rev_score of L3: [0.37952479 0.37952479 0.37952479 0.37952479 0.37952479 0.37952479
 0.37952479 0.37952479 0.37952479 0.37952479]
rev_score of L4: [0.37411021 0.37411021 0.37411021 0.37411021 0.37411021 0.37411021
 0.37411021 0.37411021 0.37411021 0.37411021]
rev_score of L5: [0.38840962 0.38840962 0.38840962 0.38840962 0.38840962 0.38840962
 0.38840962 0.38840962 0.38840962 0.38840962]
rev_score of L6: [0.35651173 0.35651173 0.35651173 0.35651173 0.35651173 0.35651173
 0.35651173 0.35651173 0.35651173 0.35651173]
rev_score of L7: [0.37521856 0.37521856 0.37521856 0.37521856 0.37521856 0.37521856
 0.37521856 0.37521856 0.37521856 0.37521856]
rev_score of L8: [0.37663528 0.37663528 0.37663528 0.37663528 0.37663528 0.37663528
 0.37663528 0.37663528 0.37663528 0.37663528]
rev_score of L9: [0.38324876 0.38324876 0.38324876 0.38324876 0.38324876 0.38324876
 0.38324876 0.38324876 0.38324876 0.38324876]
rev_score of L10: [0.36929631 0.36929631 0.36929631 0.36929631 0.36929631 0.36929631
 0.36929631 0.36929631 0.36929631 0.36929631]
rev_score of L11: [0.38526047 0.38526047 0.38526047 0.38526047 0.38526047 0.38526047
 0.38526047 0.38526047 0.38526047 0.38526047]
rev_score of L12: [0.37789241 0.37789241 0.37789241 0.37789241 0.37789241 0.37789241
 0.37789241 0.37789241 0.37789241 0.37789241]
rev_score of L13: [0.37137159 0.37137159 0.37137159 0.37137159 0.37137159 0.37137159
 0.37137159 0.37137159 0.37137159 0.37137159]
rev_score of L14: [0.37465667 0.37465667 0.37465667 0.37465667 0.37465667 0.37465667
 0.37465667 0.37465667 0.37465667 0.37465667]
rev_score of L15: [0.36875112 0.36875112 0.36875112 0.36875112 0.36875112 0.36875112
 0.36875112 0.36875112 0.36875112 0.36875112]
rev_score of L16: [0.37500535 0.37500535 0.37500535 0.37500535 0.37500535 0.37500535
 0.37500535 0.37500535 0.37500535 0.37500535]
rev_score of L17: [0.38222198 0.38222198 0.38222198 0.38222198 0.38222198 0.38222198
 0.38222198 0.38222198 0.38222198 0.38222198]
rev_score of L18: [0.38366217 0.38366217 0.38366217 0.38366217 0.38366217 0.38366217
 0.38366217 0.38366217 0.38366217 0.38366217]
rev_score of L19: [0.3849444 0.3849444 0.3849444 0.3849444 0.3849444 0.3849444 0.3849444
 0.3849444 0.3849444 0.3849444]
fwd_score of A0: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A1: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A2: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A3: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A4: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A5: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A6: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A7: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A8: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
fwd_score of A9: [0.4096  0.32768 1.      1.      1.      1.      1.      1.      1.
 1.      1.      1.      1.      1.      1.      1.      1.      1.
 1.      1.     ]
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Loss: 2.257099799073923, Acc: 0.1359
Round 14/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.32428972 -0.32428972 -0.32428972 -0.32428972 -0.32428972 -0.32428972
 -0.32428972 -0.32428972 -0.32428972 -0.32428972]
hahaha
rev_score of L1: [-0.33865 -0.33865 -0.33865 -0.33865 -0.33865 -0.33865 -0.33865 -0.33865
 -0.33865 -0.33865]
rev_score of L2: [0.39025635 0.39025635 0.39025635 0.39025635 0.39025635 0.39025635
 0.39025635 0.39025635 0.39025635 0.39025635]
rev_score of L3: [0.39368668 0.39368668 0.39368668 0.39368668 0.39368668 0.39368668
 0.39368668 0.39368668 0.39368668 0.39368668]
rev_score of L4: [0.39997508 0.39997508 0.39997508 0.39997508 0.39997508 0.39997508
 0.39997508 0.39997508 0.39997508 0.39997508]
rev_score of L5: [0.38528562 0.38528562 0.38528562 0.38528562 0.38528562 0.38528562
 0.38528562 0.38528562 0.38528562 0.38528562]
rev_score of L6: [0.37148321 0.37148321 0.37148321 0.37148321 0.37148321 0.37148321
 0.37148321 0.37148321 0.37148321 0.37148321]
rev_score of L7: [0.39242686 0.39242686 0.39242686 0.39242686 0.39242686 0.39242686
 0.39242686 0.39242686 0.39242686 0.39242686]
rev_score of L8: [0.39764539 0.39764539 0.39764539 0.39764539 0.39764539 0.39764539
 0.39764539 0.39764539 0.39764539 0.39764539]
rev_score of L9: [0.38519673 0.38519673 0.38519673 0.38519673 0.38519673 0.38519673
 0.38519673 0.38519673 0.38519673 0.38519673]
rev_score of L10: [0.37906055 0.37906055 0.37906055 0.37906055 0.37906055 0.37906055
 0.37906055 0.37906055 0.37906055 0.37906055]
rev_score of L11: [0.38544546 0.38544546 0.38544546 0.38544546 0.38544546 0.38544546
 0.38544546 0.38544546 0.38544546 0.38544546]
rev_score of L12: [0.38744251 0.38744251 0.38744251 0.38744251 0.38744251 0.38744251
 0.38744251 0.38744251 0.38744251 0.38744251]
rev_score of L13: [0.38452664 0.38452664 0.38452664 0.38452664 0.38452664 0.38452664
 0.38452664 0.38452664 0.38452664 0.38452664]
rev_score of L14: [0.38666207 0.38666207 0.38666207 0.38666207 0.38666207 0.38666207
 0.38666207 0.38666207 0.38666207 0.38666207]
rev_score of L15: [0.39742525 0.39742525 0.39742525 0.39742525 0.39742525 0.39742525
 0.39742525 0.39742525 0.39742525 0.39742525]
rev_score of L16: [0.38264839 0.38264839 0.38264839 0.38264839 0.38264839 0.38264839
 0.38264839 0.38264839 0.38264839 0.38264839]
rev_score of L17: [0.39774831 0.39774831 0.39774831 0.39774831 0.39774831 0.39774831
 0.39774831 0.39774831 0.39774831 0.39774831]
rev_score of L18: [0.38485377 0.38485377 0.38485377 0.38485377 0.38485377 0.38485377
 0.38485377 0.38485377 0.38485377 0.38485377]
rev_score of L19: [0.38247291 0.38247291 0.38247291 0.38247291 0.38247291 0.38247291
 0.38247291 0.38247291 0.38247291 0.38247291]
fwd_score of A0: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A1: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A2: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A3: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A4: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A5: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A6: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A7: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A8: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A9: [0.4096   0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Loss: 2.237954896098128, Acc: 0.1632
Round 15/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.34091147 -0.34091147 -0.34091147 -0.34091147 -0.34091147 -0.34091147
 -0.34091147 -0.34091147 -0.34091147 -0.34091147]
hahaha
rev_score of L1: [-0.33599107 -0.33599107 -0.33599107 -0.33599107 -0.33599107 -0.33599107
 -0.33599107 -0.33599107 -0.33599107 -0.33599107]
rev_score of L2: [0.44404264 0.44404264 0.44404264 0.44404264 0.44404264 0.44404264
 0.44404264 0.44404264 0.44404264 0.44404264]
rev_score of L3: [0.45060559 0.45060559 0.45060559 0.45060559 0.45060559 0.45060559
 0.45060559 0.45060559 0.45060559 0.45060559]
rev_score of L4: [0.41401854 0.41401854 0.41401854 0.41401854 0.41401854 0.41401854
 0.41401854 0.41401854 0.41401854 0.41401854]
rev_score of L5: [0.40889632 0.40889632 0.40889632 0.40889632 0.40889632 0.40889632
 0.40889632 0.40889632 0.40889632 0.40889632]
rev_score of L6: [0.44234289 0.44234289 0.44234289 0.44234289 0.44234289 0.44234289
 0.44234289 0.44234289 0.44234289 0.44234289]
rev_score of L7: [0.42967196 0.42967196 0.42967196 0.42967196 0.42967196 0.42967196
 0.42967196 0.42967196 0.42967196 0.42967196]
rev_score of L8: [0.42577306 0.42577306 0.42577306 0.42577306 0.42577306 0.42577306
 0.42577306 0.42577306 0.42577306 0.42577306]
rev_score of L9: [0.41762153 0.41762153 0.41762153 0.41762153 0.41762153 0.41762153
 0.41762153 0.41762153 0.41762153 0.41762153]
rev_score of L10: [0.43584734 0.43584734 0.43584734 0.43584734 0.43584734 0.43584734
 0.43584734 0.43584734 0.43584734 0.43584734]
rev_score of L11: [0.42818719 0.42818719 0.42818719 0.42818719 0.42818719 0.42818719
 0.42818719 0.42818719 0.42818719 0.42818719]
rev_score of L12: [0.441905 0.441905 0.441905 0.441905 0.441905 0.441905 0.441905 0.441905
 0.441905 0.441905]
rev_score of L13: [0.42808936 0.42808936 0.42808936 0.42808936 0.42808936 0.42808936
 0.42808936 0.42808936 0.42808936 0.42808936]
rev_score of L14: [0.43163775 0.43163775 0.43163775 0.43163775 0.43163775 0.43163775
 0.43163775 0.43163775 0.43163775 0.43163775]
rev_score of L15: [0.43449012 0.43449012 0.43449012 0.43449012 0.43449012 0.43449012
 0.43449012 0.43449012 0.43449012 0.43449012]
rev_score of L16: [0.42916425 0.42916425 0.42916425 0.42916425 0.42916425 0.42916425
 0.42916425 0.42916425 0.42916425 0.42916425]
rev_score of L17: [0.43651818 0.43651818 0.43651818 0.43651818 0.43651818 0.43651818
 0.43651818 0.43651818 0.43651818 0.43651818]
rev_score of L18: [0.40874155 0.40874155 0.40874155 0.40874155 0.40874155 0.40874155
 0.40874155 0.40874155 0.40874155 0.40874155]
rev_score of L19: [0.44161365 0.44161365 0.44161365 0.44161365 0.44161365 0.44161365
 0.44161365 0.44161365 0.44161365 0.44161365]
fwd_score of A0: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A1: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A2: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A3: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A4: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A5: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A6: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A7: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A8: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A9: [0.32768  0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Loss: 2.2571882866442015, Acc: 0.134
Round 16/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.33481408 -0.33481408 -0.33481408 -0.33481408 -0.33481408 -0.33481408
 -0.33481408 -0.33481408 -0.33481408 -0.33481408]
hahaha
rev_score of L1: [-0.33050281 -0.33050281 -0.33050281 -0.33050281 -0.33050281 -0.33050281
 -0.33050281 -0.33050281 -0.33050281 -0.33050281]
rev_score of L2: [0.43388286 0.43388286 0.43388286 0.43388286 0.43388286 0.43388286
 0.43388286 0.43388286 0.43388286 0.43388286]
rev_score of L3: [0.45325328 0.45325328 0.45325328 0.45325328 0.45325328 0.45325328
 0.45325328 0.45325328 0.45325328 0.45325328]
rev_score of L4: [0.43258689 0.43258689 0.43258689 0.43258689 0.43258689 0.43258689
 0.43258689 0.43258689 0.43258689 0.43258689]
rev_score of L5: [0.43854331 0.43854331 0.43854331 0.43854331 0.43854331 0.43854331
 0.43854331 0.43854331 0.43854331 0.43854331]
rev_score of L6: [0.44046292 0.44046292 0.44046292 0.44046292 0.44046292 0.44046292
 0.44046292 0.44046292 0.44046292 0.44046292]
rev_score of L7: [0.43491243 0.43491243 0.43491243 0.43491243 0.43491243 0.43491243
 0.43491243 0.43491243 0.43491243 0.43491243]
rev_score of L8: [0.44259818 0.44259818 0.44259818 0.44259818 0.44259818 0.44259818
 0.44259818 0.44259818 0.44259818 0.44259818]
rev_score of L9: [0.42785617 0.42785617 0.42785617 0.42785617 0.42785617 0.42785617
 0.42785617 0.42785617 0.42785617 0.42785617]
rev_score of L10: [0.44301893 0.44301893 0.44301893 0.44301893 0.44301893 0.44301893
 0.44301893 0.44301893 0.44301893 0.44301893]
rev_score of L11: [0.43277662 0.43277662 0.43277662 0.43277662 0.43277662 0.43277662
 0.43277662 0.43277662 0.43277662 0.43277662]
rev_score of L12: [0.44166966 0.44166966 0.44166966 0.44166966 0.44166966 0.44166966
 0.44166966 0.44166966 0.44166966 0.44166966]
rev_score of L13: [0.45119848 0.45119848 0.45119848 0.45119848 0.45119848 0.45119848
 0.45119848 0.45119848 0.45119848 0.45119848]
rev_score of L14: [0.43214481 0.43214481 0.43214481 0.43214481 0.43214481 0.43214481
 0.43214481 0.43214481 0.43214481 0.43214481]
rev_score of L15: [0.44465143 0.44465143 0.44465143 0.44465143 0.44465143 0.44465143
 0.44465143 0.44465143 0.44465143 0.44465143]
rev_score of L16: [0.42682485 0.42682485 0.42682485 0.42682485 0.42682485 0.42682485
 0.42682485 0.42682485 0.42682485 0.42682485]
rev_score of L17: [0.44981211 0.44981211 0.44981211 0.44981211 0.44981211 0.44981211
 0.44981211 0.44981211 0.44981211 0.44981211]
rev_score of L18: [0.43997839 0.43997839 0.43997839 0.43997839 0.43997839 0.43997839
 0.43997839 0.43997839 0.43997839 0.43997839]
rev_score of L19: [0.44580975 0.44580975 0.44580975 0.44580975 0.44580975 0.44580975
 0.44580975 0.44580975 0.44580975 0.44580975]
fwd_score of A0: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A1: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A2: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A3: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A4: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A5: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A6: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A7: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A8: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
fwd_score of A9: [0.262144 0.262144 1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.      ]
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Loss: 2.157791814103294, Acc: 0.155
Round 17/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.31940695 -0.31940695 -0.31940695 -0.31940695 -0.31940695 -0.31940695
 -0.31940695 -0.31940695 -0.31940695 -0.31940695]
hahaha
rev_score of L1: [-0.3216771 -0.3216771 -0.3216771 -0.3216771 -0.3216771 -0.3216771
 -0.3216771 -0.3216771 -0.3216771 -0.3216771]
rev_score of L2: [0.42048325 0.42048325 0.42048325 0.42048325 0.42048325 0.42048325
 0.42048325 0.42048325 0.42048325 0.42048325]
rev_score of L3: [0.42156545 0.42156545 0.42156545 0.42156545 0.42156545 0.42156545
 0.42156545 0.42156545 0.42156545 0.42156545]
rev_score of L4: [0.40789741 0.40789741 0.40789741 0.40789741 0.40789741 0.40789741
 0.40789741 0.40789741 0.40789741 0.40789741]
rev_score of L5: [0.40918721 0.40918721 0.40918721 0.40918721 0.40918721 0.40918721
 0.40918721 0.40918721 0.40918721 0.40918721]
rev_score of L6: [0.40009475 0.40009475 0.40009475 0.40009475 0.40009475 0.40009475
 0.40009475 0.40009475 0.40009475 0.40009475]
rev_score of L7: [0.40339144 0.40339144 0.40339144 0.40339144 0.40339144 0.40339144
 0.40339144 0.40339144 0.40339144 0.40339144]
rev_score of L8: [0.4039221 0.4039221 0.4039221 0.4039221 0.4039221 0.4039221 0.4039221
 0.4039221 0.4039221 0.4039221]
rev_score of L9: [0.40737109 0.40737109 0.40737109 0.40737109 0.40737109 0.40737109
 0.40737109 0.40737109 0.40737109 0.40737109]
rev_score of L10: [0.4282648 0.4282648 0.4282648 0.4282648 0.4282648 0.4282648 0.4282648
 0.4282648 0.4282648 0.4282648]
rev_score of L11: [0.39476241 0.39476241 0.39476241 0.39476241 0.39476241 0.39476241
 0.39476241 0.39476241 0.39476241 0.39476241]
rev_score of L12: [0.42394007 0.42394007 0.42394007 0.42394007 0.42394007 0.42394007
 0.42394007 0.42394007 0.42394007 0.42394007]
rev_score of L13: [0.42627216 0.42627216 0.42627216 0.42627216 0.42627216 0.42627216
 0.42627216 0.42627216 0.42627216 0.42627216]
rev_score of L14: [0.4109524 0.4109524 0.4109524 0.4109524 0.4109524 0.4109524 0.4109524
 0.4109524 0.4109524 0.4109524]
rev_score of L15: [0.40289699 0.40289699 0.40289699 0.40289699 0.40289699 0.40289699
 0.40289699 0.40289699 0.40289699 0.40289699]
rev_score of L16: [0.40895961 0.40895961 0.40895961 0.40895961 0.40895961 0.40895961
 0.40895961 0.40895961 0.40895961 0.40895961]
rev_score of L17: [0.40182404 0.40182404 0.40182404 0.40182404 0.40182404 0.40182404
 0.40182404 0.40182404 0.40182404 0.40182404]
rev_score of L18: [0.40660385 0.40660385 0.40660385 0.40660385 0.40660385 0.40660385
 0.40660385 0.40660385 0.40660385 0.40660385]
rev_score of L19: [0.38447224 0.38447224 0.38447224 0.38447224 0.38447224 0.38447224
 0.38447224 0.38447224 0.38447224 0.38447224]
fwd_score of A0: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A1: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A2: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A3: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A4: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A5: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A6: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A7: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A8: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
fwd_score of A9: [0.262144  0.2097152 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.       ]
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Loss: 2.229866404122057, Acc: 0.1688
Round 18/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.37596374 -0.37596374 -0.37596374 -0.37596374 -0.37596374 -0.37596374
 -0.37596374 -0.37596374 -0.37596374 -0.37596374]
hahaha
rev_score of L1: [-0.39775849 -0.39775849 -0.39775849 -0.39775849 -0.39775849 -0.39775849
 -0.39775849 -0.39775849 -0.39775849 -0.39775849]
rev_score of L2: [0.42669511 0.42669511 0.42669511 0.42669511 0.42669511 0.42669511
 0.42669511 0.42669511 0.42669511 0.42669511]
rev_score of L3: [0.44481919 0.44481919 0.44481919 0.44481919 0.44481919 0.44481919
 0.44481919 0.44481919 0.44481919 0.44481919]
rev_score of L4: [0.42809671 0.42809671 0.42809671 0.42809671 0.42809671 0.42809671
 0.42809671 0.42809671 0.42809671 0.42809671]
rev_score of L5: [0.42601705 0.42601705 0.42601705 0.42601705 0.42601705 0.42601705
 0.42601705 0.42601705 0.42601705 0.42601705]
rev_score of L6: [0.42595849 0.42595849 0.42595849 0.42595849 0.42595849 0.42595849
 0.42595849 0.42595849 0.42595849 0.42595849]
rev_score of L7: [0.44480994 0.44480994 0.44480994 0.44480994 0.44480994 0.44480994
 0.44480994 0.44480994 0.44480994 0.44480994]
rev_score of L8: [0.42792627 0.42792627 0.42792627 0.42792627 0.42792627 0.42792627
 0.42792627 0.42792627 0.42792627 0.42792627]
rev_score of L9: [0.43399232 0.43399232 0.43399232 0.43399232 0.43399232 0.43399232
 0.43399232 0.43399232 0.43399232 0.43399232]
rev_score of L10: [0.45133309 0.45133309 0.45133309 0.45133309 0.45133309 0.45133309
 0.45133309 0.45133309 0.45133309 0.45133309]
rev_score of L11: [0.43303759 0.43303759 0.43303759 0.43303759 0.43303759 0.43303759
 0.43303759 0.43303759 0.43303759 0.43303759]
rev_score of L12: [0.43331686 0.43331686 0.43331686 0.43331686 0.43331686 0.43331686
 0.43331686 0.43331686 0.43331686 0.43331686]
rev_score of L13: [0.43743034 0.43743034 0.43743034 0.43743034 0.43743034 0.43743034
 0.43743034 0.43743034 0.43743034 0.43743034]
rev_score of L14: [0.45555372 0.45555372 0.45555372 0.45555372 0.45555372 0.45555372
 0.45555372 0.45555372 0.45555372 0.45555372]
rev_score of L15: [0.43680647 0.43680647 0.43680647 0.43680647 0.43680647 0.43680647
 0.43680647 0.43680647 0.43680647 0.43680647]
rev_score of L16: [0.43200813 0.43200813 0.43200813 0.43200813 0.43200813 0.43200813
 0.43200813 0.43200813 0.43200813 0.43200813]
rev_score of L17: [0.423683 0.423683 0.423683 0.423683 0.423683 0.423683 0.423683 0.423683
 0.423683 0.423683]
rev_score of L18: [0.4415767 0.4415767 0.4415767 0.4415767 0.4415767 0.4415767 0.4415767
 0.4415767 0.4415767 0.4415767]
rev_score of L19: [0.43526725 0.43526725 0.43526725 0.43526725 0.43526725 0.43526725
 0.43526725 0.43526725 0.43526725 0.43526725]
fwd_score of A0: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.262144   0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Loss: 2.201103849532886, Acc: 0.152
Round 19/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.44588567 -0.44588567 -0.44588567 -0.44588567 -0.44588567 -0.44588567
 -0.44588567 -0.44588567 -0.44588567 -0.44588567]
hahaha
rev_score of L1: [-0.44007327 -0.44007327 -0.44007327 -0.44007327 -0.44007327 -0.44007327
 -0.44007327 -0.44007327 -0.44007327 -0.44007327]
rev_score of L2: [0.48525699 0.48525699 0.48525699 0.48525699 0.48525699 0.48525699
 0.48525699 0.48525699 0.48525699 0.48525699]
rev_score of L3: [0.4743602 0.4743602 0.4743602 0.4743602 0.4743602 0.4743602 0.4743602
 0.4743602 0.4743602 0.4743602]
rev_score of L4: [0.48723795 0.48723795 0.48723795 0.48723795 0.48723795 0.48723795
 0.48723795 0.48723795 0.48723795 0.48723795]
rev_score of L5: [0.47038037 0.47038037 0.47038037 0.47038037 0.47038037 0.47038037
 0.47038037 0.47038037 0.47038037 0.47038037]
rev_score of L6: [0.46958416 0.46958416 0.46958416 0.46958416 0.46958416 0.46958416
 0.46958416 0.46958416 0.46958416 0.46958416]
rev_score of L7: [0.48405352 0.48405352 0.48405352 0.48405352 0.48405352 0.48405352
 0.48405352 0.48405352 0.48405352 0.48405352]
rev_score of L8: [0.47155194 0.47155194 0.47155194 0.47155194 0.47155194 0.47155194
 0.47155194 0.47155194 0.47155194 0.47155194]
rev_score of L9: [0.47784883 0.47784883 0.47784883 0.47784883 0.47784883 0.47784883
 0.47784883 0.47784883 0.47784883 0.47784883]
rev_score of L10: [0.46253378 0.46253378 0.46253378 0.46253378 0.46253378 0.46253378
 0.46253378 0.46253378 0.46253378 0.46253378]
rev_score of L11: [0.48088675 0.48088675 0.48088675 0.48088675 0.48088675 0.48088675
 0.48088675 0.48088675 0.48088675 0.48088675]
rev_score of L12: [0.47899107 0.47899107 0.47899107 0.47899107 0.47899107 0.47899107
 0.47899107 0.47899107 0.47899107 0.47899107]
rev_score of L13: [0.47505647 0.47505647 0.47505647 0.47505647 0.47505647 0.47505647
 0.47505647 0.47505647 0.47505647 0.47505647]
rev_score of L14: [0.47460208 0.47460208 0.47460208 0.47460208 0.47460208 0.47460208
 0.47460208 0.47460208 0.47460208 0.47460208]
rev_score of L15: [0.48008509 0.48008509 0.48008509 0.48008509 0.48008509 0.48008509
 0.48008509 0.48008509 0.48008509 0.48008509]
rev_score of L16: [0.47551614 0.47551614 0.47551614 0.47551614 0.47551614 0.47551614
 0.47551614 0.47551614 0.47551614 0.47551614]
rev_score of L17: [0.47495502 0.47495502 0.47495502 0.47495502 0.47495502 0.47495502
 0.47495502 0.47495502 0.47495502 0.47495502]
rev_score of L18: [0.47091559 0.47091559 0.47091559 0.47091559 0.47091559 0.47091559
 0.47091559 0.47091559 0.47091559 0.47091559]
rev_score of L19: [0.47322957 0.47322957 0.47322957 0.47322957 0.47322957 0.47322957
 0.47322957 0.47322957 0.47322957 0.47322957]
fwd_score of A0: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.2097152  0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Loss: 2.212590572552178, Acc: 0.1382
Round 20/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.40793141 -0.40793141 -0.40793141 -0.40793141 -0.40793141 -0.40793141
 -0.40793141 -0.40793141 -0.40793141 -0.40793141]
hahaha
rev_score of L1: [-0.40033939 -0.40033939 -0.40033939 -0.40033939 -0.40033939 -0.40033939
 -0.40033939 -0.40033939 -0.40033939 -0.40033939]
rev_score of L2: [0.43773094 0.43773094 0.43773094 0.43773094 0.43773094 0.43773094
 0.43773094 0.43773094 0.43773094 0.43773094]
rev_score of L3: [0.439229 0.439229 0.439229 0.439229 0.439229 0.439229 0.439229 0.439229
 0.439229 0.439229]
rev_score of L4: [0.45037722 0.45037722 0.45037722 0.45037722 0.45037722 0.45037722
 0.45037722 0.45037722 0.45037722 0.45037722]
rev_score of L5: [0.44002149 0.44002149 0.44002149 0.44002149 0.44002149 0.44002149
 0.44002149 0.44002149 0.44002149 0.44002149]
rev_score of L6: [0.44179409 0.44179409 0.44179409 0.44179409 0.44179409 0.44179409
 0.44179409 0.44179409 0.44179409 0.44179409]
rev_score of L7: [0.45022 0.45022 0.45022 0.45022 0.45022 0.45022 0.45022 0.45022 0.45022
 0.45022]
rev_score of L8: [0.43932391 0.43932391 0.43932391 0.43932391 0.43932391 0.43932391
 0.43932391 0.43932391 0.43932391 0.43932391]
rev_score of L9: [0.43234732 0.43234732 0.43234732 0.43234732 0.43234732 0.43234732
 0.43234732 0.43234732 0.43234732 0.43234732]
rev_score of L10: [0.44950605 0.44950605 0.44950605 0.44950605 0.44950605 0.44950605
 0.44950605 0.44950605 0.44950605 0.44950605]
rev_score of L11: [0.43630377 0.43630377 0.43630377 0.43630377 0.43630377 0.43630377
 0.43630377 0.43630377 0.43630377 0.43630377]
rev_score of L12: [0.4345775 0.4345775 0.4345775 0.4345775 0.4345775 0.4345775 0.4345775
 0.4345775 0.4345775 0.4345775]
rev_score of L13: [0.4491858 0.4491858 0.4491858 0.4491858 0.4491858 0.4491858 0.4491858
 0.4491858 0.4491858 0.4491858]
rev_score of L14: [0.42924335 0.42924335 0.42924335 0.42924335 0.42924335 0.42924335
 0.42924335 0.42924335 0.42924335 0.42924335]
rev_score of L15: [0.43423628 0.43423628 0.43423628 0.43423628 0.43423628 0.43423628
 0.43423628 0.43423628 0.43423628 0.43423628]
rev_score of L16: [0.43952485 0.43952485 0.43952485 0.43952485 0.43952485 0.43952485
 0.43952485 0.43952485 0.43952485 0.43952485]
rev_score of L17: [0.44536592 0.44536592 0.44536592 0.44536592 0.44536592 0.44536592
 0.44536592 0.44536592 0.44536592 0.44536592]
rev_score of L18: [0.4460572 0.4460572 0.4460572 0.4460572 0.4460572 0.4460572 0.4460572
 0.4460572 0.4460572 0.4460572]
rev_score of L19: [0.45240986 0.45240986 0.45240986 0.45240986 0.45240986 0.45240986
 0.45240986 0.45240986 0.45240986 0.45240986]
fwd_score of A0: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.16777216 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Loss: 2.129143979983589, Acc: 0.2066
Round 21/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.37556877 -0.37556877 -0.37556877 -0.37556877 -0.37556877 -0.37556877
 -0.37556877 -0.37556877 -0.37556877 -0.37556877]
hahaha
rev_score of L1: [-0.40042017 -0.40042017 -0.40042017 -0.40042017 -0.40042017 -0.40042017
 -0.40042017 -0.40042017 -0.40042017 -0.40042017]
rev_score of L2: [0.46039139 0.46039139 0.46039139 0.46039139 0.46039139 0.46039139
 0.46039139 0.46039139 0.46039139 0.46039139]
rev_score of L3: [0.4578988 0.4578988 0.4578988 0.4578988 0.4578988 0.4578988 0.4578988
 0.4578988 0.4578988 0.4578988]
rev_score of L4: [0.43182194 0.43182194 0.43182194 0.43182194 0.43182194 0.43182194
 0.43182194 0.43182194 0.43182194 0.43182194]
rev_score of L5: [0.44434918 0.44434918 0.44434918 0.44434918 0.44434918 0.44434918
 0.44434918 0.44434918 0.44434918 0.44434918]
rev_score of L6: [0.46056963 0.46056963 0.46056963 0.46056963 0.46056963 0.46056963
 0.46056963 0.46056963 0.46056963 0.46056963]
rev_score of L7: [0.45068028 0.45068028 0.45068028 0.45068028 0.45068028 0.45068028
 0.45068028 0.45068028 0.45068028 0.45068028]
rev_score of L8: [0.45548272 0.45548272 0.45548272 0.45548272 0.45548272 0.45548272
 0.45548272 0.45548272 0.45548272 0.45548272]
rev_score of L9: [0.45674736 0.45674736 0.45674736 0.45674736 0.45674736 0.45674736
 0.45674736 0.45674736 0.45674736 0.45674736]
rev_score of L10: [0.44163565 0.44163565 0.44163565 0.44163565 0.44163565 0.44163565
 0.44163565 0.44163565 0.44163565 0.44163565]
rev_score of L11: [0.45433485 0.45433485 0.45433485 0.45433485 0.45433485 0.45433485
 0.45433485 0.45433485 0.45433485 0.45433485]
rev_score of L12: [0.4467132 0.4467132 0.4467132 0.4467132 0.4467132 0.4467132 0.4467132
 0.4467132 0.4467132 0.4467132]
rev_score of L13: [0.46243767 0.46243767 0.46243767 0.46243767 0.46243767 0.46243767
 0.46243767 0.46243767 0.46243767 0.46243767]
rev_score of L14: [0.43805505 0.43805505 0.43805505 0.43805505 0.43805505 0.43805505
 0.43805505 0.43805505 0.43805505 0.43805505]
rev_score of L15: [0.45686912 0.45686912 0.45686912 0.45686912 0.45686912 0.45686912
 0.45686912 0.45686912 0.45686912 0.45686912]
rev_score of L16: [0.44613005 0.44613005 0.44613005 0.44613005 0.44613005 0.44613005
 0.44613005 0.44613005 0.44613005 0.44613005]
rev_score of L17: [0.44794579 0.44794579 0.44794579 0.44794579 0.44794579 0.44794579
 0.44794579 0.44794579 0.44794579 0.44794579]
rev_score of L18: [0.46236909 0.46236909 0.46236909 0.46236909 0.46236909 0.46236909
 0.46236909 0.46236909 0.46236909 0.46236909]
rev_score of L19: [0.47281676 0.47281676 0.47281676 0.47281676 0.47281676 0.47281676
 0.47281676 0.47281676 0.47281676 0.47281676]
fwd_score of A0: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.13421773 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Loss: 2.098880550351006, Acc: 0.2361
Round 22/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.39080689 -0.39080689 -0.39080689 -0.39080689 -0.39080689 -0.39080689
 -0.39080689 -0.39080689 -0.39080689 -0.39080689]
hahaha
rev_score of L1: [-0.39393058 -0.39393058 -0.39393058 -0.39393058 -0.39393058 -0.39393058
 -0.39393058 -0.39393058 -0.39393058 -0.39393058]
rev_score of L2: [0.47280076 0.47280076 0.47280076 0.47280076 0.47280076 0.47280076
 0.47280076 0.47280076 0.47280076 0.47280076]
rev_score of L3: [0.46373352 0.46373352 0.46373352 0.46373352 0.46373352 0.46373352
 0.46373352 0.46373352 0.46373352 0.46373352]
rev_score of L4: [0.45076979 0.45076979 0.45076979 0.45076979 0.45076979 0.45076979
 0.45076979 0.45076979 0.45076979 0.45076979]
rev_score of L5: [0.44721002 0.44721002 0.44721002 0.44721002 0.44721002 0.44721002
 0.44721002 0.44721002 0.44721002 0.44721002]
rev_score of L6: [0.45956809 0.45956809 0.45956809 0.45956809 0.45956809 0.45956809
 0.45956809 0.45956809 0.45956809 0.45956809]
rev_score of L7: [0.45576478 0.45576478 0.45576478 0.45576478 0.45576478 0.45576478
 0.45576478 0.45576478 0.45576478 0.45576478]
rev_score of L8: [0.44564263 0.44564263 0.44564263 0.44564263 0.44564263 0.44564263
 0.44564263 0.44564263 0.44564263 0.44564263]
rev_score of L9: [0.45199014 0.45199014 0.45199014 0.45199014 0.45199014 0.45199014
 0.45199014 0.45199014 0.45199014 0.45199014]
rev_score of L10: [0.46172598 0.46172598 0.46172598 0.46172598 0.46172598 0.46172598
 0.46172598 0.46172598 0.46172598 0.46172598]
rev_score of L11: [0.45969114 0.45969114 0.45969114 0.45969114 0.45969114 0.45969114
 0.45969114 0.45969114 0.45969114 0.45969114]
rev_score of L12: [0.4543376 0.4543376 0.4543376 0.4543376 0.4543376 0.4543376 0.4543376
 0.4543376 0.4543376 0.4543376]
rev_score of L13: [0.46736266 0.46736266 0.46736266 0.46736266 0.46736266 0.46736266
 0.46736266 0.46736266 0.46736266 0.46736266]
rev_score of L14: [0.45323246 0.45323246 0.45323246 0.45323246 0.45323246 0.45323246
 0.45323246 0.45323246 0.45323246 0.45323246]
rev_score of L15: [0.46069729 0.46069729 0.46069729 0.46069729 0.46069729 0.46069729
 0.46069729 0.46069729 0.46069729 0.46069729]
rev_score of L16: [0.456791 0.456791 0.456791 0.456791 0.456791 0.456791 0.456791 0.456791
 0.456791 0.456791]
rev_score of L17: [0.45622472 0.45622472 0.45622472 0.45622472 0.45622472 0.45622472
 0.45622472 0.45622472 0.45622472 0.45622472]
rev_score of L18: [0.44594449 0.44594449 0.44594449 0.44594449 0.44594449 0.44594449
 0.44594449 0.44594449 0.44594449 0.44594449]
rev_score of L19: [0.45768289 0.45768289 0.45768289 0.45768289 0.45768289 0.45768289
 0.45768289 0.45768289 0.45768289 0.45768289]
fwd_score of A0: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.10737418 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Loss: 2.2212659589017925, Acc: 0.1647
Round 23/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.36766416 -0.36766416 -0.36766416 -0.36766416 -0.36766416 -0.36766416
 -0.36766416 -0.36766416 -0.36766416 -0.36766416]
hahaha
rev_score of L1: [-0.3710868 -0.3710868 -0.3710868 -0.3710868 -0.3710868 -0.3710868
 -0.3710868 -0.3710868 -0.3710868 -0.3710868]
rev_score of L2: [0.45721046 0.45721046 0.45721046 0.45721046 0.45721046 0.45721046
 0.45721046 0.45721046 0.45721046 0.45721046]
rev_score of L3: [0.45023688 0.45023688 0.45023688 0.45023688 0.45023688 0.45023688
 0.45023688 0.45023688 0.45023688 0.45023688]
rev_score of L4: [0.4427809 0.4427809 0.4427809 0.4427809 0.4427809 0.4427809 0.4427809
 0.4427809 0.4427809 0.4427809]
rev_score of L5: [0.4512401 0.4512401 0.4512401 0.4512401 0.4512401 0.4512401 0.4512401
 0.4512401 0.4512401 0.4512401]
rev_score of L6: [0.44358587 0.44358587 0.44358587 0.44358587 0.44358587 0.44358587
 0.44358587 0.44358587 0.44358587 0.44358587]
rev_score of L7: [0.43569983 0.43569983 0.43569983 0.43569983 0.43569983 0.43569983
 0.43569983 0.43569983 0.43569983 0.43569983]
rev_score of L8: [0.46954541 0.46954541 0.46954541 0.46954541 0.46954541 0.46954541
 0.46954541 0.46954541 0.46954541 0.46954541]
rev_score of L9: [0.46289332 0.46289332 0.46289332 0.46289332 0.46289332 0.46289332
 0.46289332 0.46289332 0.46289332 0.46289332]
rev_score of L10: [0.47597754 0.47597754 0.47597754 0.47597754 0.47597754 0.47597754
 0.47597754 0.47597754 0.47597754 0.47597754]
rev_score of L11: [0.45263138 0.45263138 0.45263138 0.45263138 0.45263138 0.45263138
 0.45263138 0.45263138 0.45263138 0.45263138]
rev_score of L12: [0.45447809 0.45447809 0.45447809 0.45447809 0.45447809 0.45447809
 0.45447809 0.45447809 0.45447809 0.45447809]
rev_score of L13: [0.45138172 0.45138172 0.45138172 0.45138172 0.45138172 0.45138172
 0.45138172 0.45138172 0.45138172 0.45138172]
rev_score of L14: [0.47510926 0.47510926 0.47510926 0.47510926 0.47510926 0.47510926
 0.47510926 0.47510926 0.47510926 0.47510926]
rev_score of L15: [0.45280999 0.45280999 0.45280999 0.45280999 0.45280999 0.45280999
 0.45280999 0.45280999 0.45280999 0.45280999]
rev_score of L16: [0.46073122 0.46073122 0.46073122 0.46073122 0.46073122 0.46073122
 0.46073122 0.46073122 0.46073122 0.46073122]
rev_score of L17: [0.46469154 0.46469154 0.46469154 0.46469154 0.46469154 0.46469154
 0.46469154 0.46469154 0.46469154 0.46469154]
rev_score of L18: [0.44573089 0.44573089 0.44573089 0.44573089 0.44573089 0.44573089
 0.44573089 0.44573089 0.44573089 0.44573089]
rev_score of L19: [0.44904896 0.44904896 0.44904896 0.44904896 0.44904896 0.44904896
 0.44904896 0.44904896 0.44904896 0.44904896]
fwd_score of A0: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.08589935 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Loss: 2.2003089665604856, Acc: 0.1638
Round 24/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.40329182 -0.40329182 -0.40329182 -0.40329182 -0.40329182 -0.40329182
 -0.40329182 -0.40329182 -0.40329182 -0.40329182]
hahaha
rev_score of L1: [-0.41286836 -0.41286836 -0.41286836 -0.41286836 -0.41286836 -0.41286836
 -0.41286836 -0.41286836 -0.41286836 -0.41286836]
rev_score of L2: [0.46819587 0.46819587 0.46819587 0.46819587 0.46819587 0.46819587
 0.46819587 0.46819587 0.46819587 0.46819587]
rev_score of L3: [0.467537 0.467537 0.467537 0.467537 0.467537 0.467537 0.467537 0.467537
 0.467537 0.467537]
rev_score of L4: [0.46917653 0.46917653 0.46917653 0.46917653 0.46917653 0.46917653
 0.46917653 0.46917653 0.46917653 0.46917653]
rev_score of L5: [0.47300786 0.47300786 0.47300786 0.47300786 0.47300786 0.47300786
 0.47300786 0.47300786 0.47300786 0.47300786]
rev_score of L6: [0.4661113 0.4661113 0.4661113 0.4661113 0.4661113 0.4661113 0.4661113
 0.4661113 0.4661113 0.4661113]
rev_score of L7: [0.46878466 0.46878466 0.46878466 0.46878466 0.46878466 0.46878466
 0.46878466 0.46878466 0.46878466 0.46878466]
rev_score of L8: [0.46673668 0.46673668 0.46673668 0.46673668 0.46673668 0.46673668
 0.46673668 0.46673668 0.46673668 0.46673668]
rev_score of L9: [0.47075237 0.47075237 0.47075237 0.47075237 0.47075237 0.47075237
 0.47075237 0.47075237 0.47075237 0.47075237]
rev_score of L10: [0.47856594 0.47856594 0.47856594 0.47856594 0.47856594 0.47856594
 0.47856594 0.47856594 0.47856594 0.47856594]
rev_score of L11: [0.47192901 0.47192901 0.47192901 0.47192901 0.47192901 0.47192901
 0.47192901 0.47192901 0.47192901 0.47192901]
rev_score of L12: [0.47208815 0.47208815 0.47208815 0.47208815 0.47208815 0.47208815
 0.47208815 0.47208815 0.47208815 0.47208815]
rev_score of L13: [0.47183028 0.47183028 0.47183028 0.47183028 0.47183028 0.47183028
 0.47183028 0.47183028 0.47183028 0.47183028]
rev_score of L14: [0.47138395 0.47138395 0.47138395 0.47138395 0.47138395 0.47138395
 0.47138395 0.47138395 0.47138395 0.47138395]
rev_score of L15: [0.47845705 0.47845705 0.47845705 0.47845705 0.47845705 0.47845705
 0.47845705 0.47845705 0.47845705 0.47845705]
rev_score of L16: [0.47550746 0.47550746 0.47550746 0.47550746 0.47550746 0.47550746
 0.47550746 0.47550746 0.47550746 0.47550746]
rev_score of L17: [0.48228703 0.48228703 0.48228703 0.48228703 0.48228703 0.48228703
 0.48228703 0.48228703 0.48228703 0.48228703]
rev_score of L18: [0.46956551 0.46956551 0.46956551 0.46956551 0.46956551 0.46956551
 0.46956551 0.46956551 0.46956551 0.46956551]
rev_score of L19: [0.46007023 0.46007023 0.46007023 0.46007023 0.46007023 0.46007023
 0.46007023 0.46007023 0.46007023 0.46007023]
fwd_score of A0: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.06871948 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Loss: 2.1916837966480194, Acc: 0.156
Round 25/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.41750973 -0.41750973 -0.41750973 -0.41750973 -0.41750973 -0.41750973
 -0.41750973 -0.41750973 -0.41750973 -0.41750973]
hahaha
rev_score of L1: [-0.41998414 -0.41998414 -0.41998414 -0.41998414 -0.41998414 -0.41998414
 -0.41998414 -0.41998414 -0.41998414 -0.41998414]
rev_score of L2: [0.46560448 0.46560448 0.46560448 0.46560448 0.46560448 0.46560448
 0.46560448 0.46560448 0.46560448 0.46560448]
rev_score of L3: [0.48671326 0.48671326 0.48671326 0.48671326 0.48671326 0.48671326
 0.48671326 0.48671326 0.48671326 0.48671326]
rev_score of L4: [0.47574468 0.47574468 0.47574468 0.47574468 0.47574468 0.47574468
 0.47574468 0.47574468 0.47574468 0.47574468]
rev_score of L5: [0.47535827 0.47535827 0.47535827 0.47535827 0.47535827 0.47535827
 0.47535827 0.47535827 0.47535827 0.47535827]
rev_score of L6: [0.47018926 0.47018926 0.47018926 0.47018926 0.47018926 0.47018926
 0.47018926 0.47018926 0.47018926 0.47018926]
rev_score of L7: [0.49149988 0.49149988 0.49149988 0.49149988 0.49149988 0.49149988
 0.49149988 0.49149988 0.49149988 0.49149988]
rev_score of L8: [0.47654029 0.47654029 0.47654029 0.47654029 0.47654029 0.47654029
 0.47654029 0.47654029 0.47654029 0.47654029]
rev_score of L9: [0.46682544 0.46682544 0.46682544 0.46682544 0.46682544 0.46682544
 0.46682544 0.46682544 0.46682544 0.46682544]
rev_score of L10: [0.4719184 0.4719184 0.4719184 0.4719184 0.4719184 0.4719184 0.4719184
 0.4719184 0.4719184 0.4719184]
rev_score of L11: [0.47229595 0.47229595 0.47229595 0.47229595 0.47229595 0.47229595
 0.47229595 0.47229595 0.47229595 0.47229595]
rev_score of L12: [0.48204194 0.48204194 0.48204194 0.48204194 0.48204194 0.48204194
 0.48204194 0.48204194 0.48204194 0.48204194]
rev_score of L13: [0.48192063 0.48192063 0.48192063 0.48192063 0.48192063 0.48192063
 0.48192063 0.48192063 0.48192063 0.48192063]
rev_score of L14: [0.46884479 0.46884479 0.46884479 0.46884479 0.46884479 0.46884479
 0.46884479 0.46884479 0.46884479 0.46884479]
rev_score of L15: [0.47177614 0.47177614 0.47177614 0.47177614 0.47177614 0.47177614
 0.47177614 0.47177614 0.47177614 0.47177614]
rev_score of L16: [0.48284716 0.48284716 0.48284716 0.48284716 0.48284716 0.48284716
 0.48284716 0.48284716 0.48284716 0.48284716]
rev_score of L17: [0.47583971 0.47583971 0.47583971 0.47583971 0.47583971 0.47583971
 0.47583971 0.47583971 0.47583971 0.47583971]
rev_score of L18: [0.47545277 0.47545277 0.47545277 0.47545277 0.47545277 0.47545277
 0.47545277 0.47545277 0.47545277 0.47545277]
rev_score of L19: [0.47561545 0.47561545 0.47561545 0.47561545 0.47561545 0.47561545
 0.47561545 0.47561545 0.47561545 0.47561545]
fwd_score of A0: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.16777216 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Loss: 2.1113715236560227, Acc: 0.1951
Round 26/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.42472787 -0.42472787 -0.42472787 -0.42472787 -0.42472787 -0.42472787
 -0.42472787 -0.42472787 -0.42472787 -0.42472787]
hahaha
rev_score of L1: [-0.4223616 -0.4223616 -0.4223616 -0.4223616 -0.4223616 -0.4223616
 -0.4223616 -0.4223616 -0.4223616 -0.4223616]
rev_score of L2: [0.47627482 0.47627482 0.47627482 0.47627482 0.47627482 0.47627482
 0.47627482 0.47627482 0.47627482 0.47627482]
rev_score of L3: [0.47129131 0.47129131 0.47129131 0.47129131 0.47129131 0.47129131
 0.47129131 0.47129131 0.47129131 0.47129131]
rev_score of L4: [0.48281279 0.48281279 0.48281279 0.48281279 0.48281279 0.48281279
 0.48281279 0.48281279 0.48281279 0.48281279]
rev_score of L5: [0.48078496 0.48078496 0.48078496 0.48078496 0.48078496 0.48078496
 0.48078496 0.48078496 0.48078496 0.48078496]
rev_score of L6: [0.47234227 0.47234227 0.47234227 0.47234227 0.47234227 0.47234227
 0.47234227 0.47234227 0.47234227 0.47234227]
rev_score of L7: [0.4777073 0.4777073 0.4777073 0.4777073 0.4777073 0.4777073 0.4777073
 0.4777073 0.4777073 0.4777073]
rev_score of L8: [0.48314589 0.48314589 0.48314589 0.48314589 0.48314589 0.48314589
 0.48314589 0.48314589 0.48314589 0.48314589]
rev_score of L9: [0.48864983 0.48864983 0.48864983 0.48864983 0.48864983 0.48864983
 0.48864983 0.48864983 0.48864983 0.48864983]
rev_score of L10: [0.48211425 0.48211425 0.48211425 0.48211425 0.48211425 0.48211425
 0.48211425 0.48211425 0.48211425 0.48211425]
rev_score of L11: [0.49125219 0.49125219 0.49125219 0.49125219 0.49125219 0.49125219
 0.49125219 0.49125219 0.49125219 0.49125219]
rev_score of L12: [0.48274911 0.48274911 0.48274911 0.48274911 0.48274911 0.48274911
 0.48274911 0.48274911 0.48274911 0.48274911]
rev_score of L13: [0.48077981 0.48077981 0.48077981 0.48077981 0.48077981 0.48077981
 0.48077981 0.48077981 0.48077981 0.48077981]
rev_score of L14: [0.4722278 0.4722278 0.4722278 0.4722278 0.4722278 0.4722278 0.4722278
 0.4722278 0.4722278 0.4722278]
rev_score of L15: [0.4715885 0.4715885 0.4715885 0.4715885 0.4715885 0.4715885 0.4715885
 0.4715885 0.4715885 0.4715885]
rev_score of L16: [0.48184846 0.48184846 0.48184846 0.48184846 0.48184846 0.48184846
 0.48184846 0.48184846 0.48184846 0.48184846]
rev_score of L17: [0.47103033 0.47103033 0.47103033 0.47103033 0.47103033 0.47103033
 0.47103033 0.47103033 0.47103033 0.47103033]
rev_score of L18: [0.48559329 0.48559329 0.48559329 0.48559329 0.48559329 0.48559329
 0.48559329 0.48559329 0.48559329 0.48559329]
rev_score of L19: [0.47483136 0.47483136 0.47483136 0.47483136 0.47483136 0.47483136
 0.47483136 0.47483136 0.47483136 0.47483136]
fwd_score of A0: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.13421773 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Loss: 2.110906081458631, Acc: 0.2407
Round 27/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.44103754 -0.44103754 -0.44103754 -0.44103754 -0.44103754 -0.44103754
 -0.44103754 -0.44103754 -0.44103754 -0.44103754]
hahaha
rev_score of L1: [-0.43878214 -0.43878214 -0.43878214 -0.43878214 -0.43878214 -0.43878214
 -0.43878214 -0.43878214 -0.43878214 -0.43878214]
rev_score of L2: [0.48960826 0.48960826 0.48960826 0.48960826 0.48960826 0.48960826
 0.48960826 0.48960826 0.48960826 0.48960826]
rev_score of L3: [0.48289536 0.48289536 0.48289536 0.48289536 0.48289536 0.48289536
 0.48289536 0.48289536 0.48289536 0.48289536]
rev_score of L4: [0.49348021 0.49348021 0.49348021 0.49348021 0.49348021 0.49348021
 0.49348021 0.49348021 0.49348021 0.49348021]
rev_score of L5: [0.4811167 0.4811167 0.4811167 0.4811167 0.4811167 0.4811167 0.4811167
 0.4811167 0.4811167 0.4811167]
rev_score of L6: [0.48270989 0.48270989 0.48270989 0.48270989 0.48270989 0.48270989
 0.48270989 0.48270989 0.48270989 0.48270989]
rev_score of L7: [0.48204904 0.48204904 0.48204904 0.48204904 0.48204904 0.48204904
 0.48204904 0.48204904 0.48204904 0.48204904]
rev_score of L8: [0.48086863 0.48086863 0.48086863 0.48086863 0.48086863 0.48086863
 0.48086863 0.48086863 0.48086863 0.48086863]
rev_score of L9: [0.48476764 0.48476764 0.48476764 0.48476764 0.48476764 0.48476764
 0.48476764 0.48476764 0.48476764 0.48476764]
rev_score of L10: [0.47775252 0.47775252 0.47775252 0.47775252 0.47775252 0.47775252
 0.47775252 0.47775252 0.47775252 0.47775252]
rev_score of L11: [0.4935593 0.4935593 0.4935593 0.4935593 0.4935593 0.4935593 0.4935593
 0.4935593 0.4935593 0.4935593]
rev_score of L12: [0.48578087 0.48578087 0.48578087 0.48578087 0.48578087 0.48578087
 0.48578087 0.48578087 0.48578087 0.48578087]
rev_score of L13: [0.47678621 0.47678621 0.47678621 0.47678621 0.47678621 0.47678621
 0.47678621 0.47678621 0.47678621 0.47678621]
rev_score of L14: [0.48763154 0.48763154 0.48763154 0.48763154 0.48763154 0.48763154
 0.48763154 0.48763154 0.48763154 0.48763154]
rev_score of L15: [0.48032251 0.48032251 0.48032251 0.48032251 0.48032251 0.48032251
 0.48032251 0.48032251 0.48032251 0.48032251]
rev_score of L16: [0.47997836 0.47997836 0.47997836 0.47997836 0.47997836 0.47997836
 0.47997836 0.47997836 0.47997836 0.47997836]
rev_score of L17: [0.47897723 0.47897723 0.47897723 0.47897723 0.47897723 0.47897723
 0.47897723 0.47897723 0.47897723 0.47897723]
rev_score of L18: [0.48940162 0.48940162 0.48940162 0.48940162 0.48940162 0.48940162
 0.48940162 0.48940162 0.48940162 0.48940162]
rev_score of L19: [0.49214999 0.49214999 0.49214999 0.49214999 0.49214999 0.49214999
 0.49214999 0.49214999 0.49214999 0.49214999]
fwd_score of A0: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.10737418 0.05497558 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Loss: 2.1639578974665925, Acc: 0.1894
Round 28/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.43010397 -0.43010397 -0.43010397 -0.43010397 -0.43010397 -0.43010397
 -0.43010397 -0.43010397 -0.43010397 -0.43010397]
hahaha
rev_score of L1: [-0.43312265 -0.43312265 -0.43312265 -0.43312265 -0.43312265 -0.43312265
 -0.43312265 -0.43312265 -0.43312265 -0.43312265]
rev_score of L2: [0.48511344 0.48511344 0.48511344 0.48511344 0.48511344 0.48511344
 0.48511344 0.48511344 0.48511344 0.48511344]
rev_score of L3: [0.49922203 0.49922203 0.49922203 0.49922203 0.49922203 0.49922203
 0.49922203 0.49922203 0.49922203 0.49922203]
rev_score of L4: [0.48722179 0.48722179 0.48722179 0.48722179 0.48722179 0.48722179
 0.48722179 0.48722179 0.48722179 0.48722179]
rev_score of L5: [0.49507615 0.49507615 0.49507615 0.49507615 0.49507615 0.49507615
 0.49507615 0.49507615 0.49507615 0.49507615]
rev_score of L6: [0.48981095 0.48981095 0.48981095 0.48981095 0.48981095 0.48981095
 0.48981095 0.48981095 0.48981095 0.48981095]
rev_score of L7: [0.49607693 0.49607693 0.49607693 0.49607693 0.49607693 0.49607693
 0.49607693 0.49607693 0.49607693 0.49607693]
rev_score of L8: [0.47998153 0.47998153 0.47998153 0.47998153 0.47998153 0.47998153
 0.47998153 0.47998153 0.47998153 0.47998153]
rev_score of L9: [0.4808289 0.4808289 0.4808289 0.4808289 0.4808289 0.4808289 0.4808289
 0.4808289 0.4808289 0.4808289]
rev_score of L10: [0.4877664 0.4877664 0.4877664 0.4877664 0.4877664 0.4877664 0.4877664
 0.4877664 0.4877664 0.4877664]
rev_score of L11: [0.49611663 0.49611663 0.49611663 0.49611663 0.49611663 0.49611663
 0.49611663 0.49611663 0.49611663 0.49611663]
rev_score of L12: [0.48009754 0.48009754 0.48009754 0.48009754 0.48009754 0.48009754
 0.48009754 0.48009754 0.48009754 0.48009754]
rev_score of L13: [0.49911203 0.49911203 0.49911203 0.49911203 0.49911203 0.49911203
 0.49911203 0.49911203 0.49911203 0.49911203]
rev_score of L14: [0.48956813 0.48956813 0.48956813 0.48956813 0.48956813 0.48956813
 0.48956813 0.48956813 0.48956813 0.48956813]
rev_score of L15: [0.48784237 0.48784237 0.48784237 0.48784237 0.48784237 0.48784237
 0.48784237 0.48784237 0.48784237 0.48784237]
rev_score of L16: [0.49103913 0.49103913 0.49103913 0.49103913 0.49103913 0.49103913
 0.49103913 0.49103913 0.49103913 0.49103913]
rev_score of L17: [0.49136157 0.49136157 0.49136157 0.49136157 0.49136157 0.49136157
 0.49136157 0.49136157 0.49136157 0.49136157]
rev_score of L18: [0.481286 0.481286 0.481286 0.481286 0.481286 0.481286 0.481286 0.481286
 0.481286 0.481286]
rev_score of L19: [0.49716571 0.49716571 0.49716571 0.49716571 0.49716571 0.49716571
 0.49716571 0.49716571 0.49716571 0.49716571]
fwd_score of A0: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.10737418 0.04398047 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Loss: 2.380953006470165, Acc: 0.1283
Round 29/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.41563082 -0.41563082 -0.41563082 -0.41563082 -0.41563082 -0.41563082
 -0.41563082 -0.41563082 -0.41563082 -0.41563082]
hahaha
rev_score of L1: [-0.41646808 -0.41646808 -0.41646808 -0.41646808 -0.41646808 -0.41646808
 -0.41646808 -0.41646808 -0.41646808 -0.41646808]
rev_score of L2: [0.48845403 0.48845403 0.48845403 0.48845403 0.48845403 0.48845403
 0.48845403 0.48845403 0.48845403 0.48845403]
rev_score of L3: [0.4802471 0.4802471 0.4802471 0.4802471 0.4802471 0.4802471 0.4802471
 0.4802471 0.4802471 0.4802471]
rev_score of L4: [0.47494319 0.47494319 0.47494319 0.47494319 0.47494319 0.47494319
 0.47494319 0.47494319 0.47494319 0.47494319]
rev_score of L5: [0.47086479 0.47086479 0.47086479 0.47086479 0.47086479 0.47086479
 0.47086479 0.47086479 0.47086479 0.47086479]
rev_score of L6: [0.47327905 0.47327905 0.47327905 0.47327905 0.47327905 0.47327905
 0.47327905 0.47327905 0.47327905 0.47327905]
rev_score of L7: [0.47620927 0.47620927 0.47620927 0.47620927 0.47620927 0.47620927
 0.47620927 0.47620927 0.47620927 0.47620927]
rev_score of L8: [0.48348116 0.48348116 0.48348116 0.48348116 0.48348116 0.48348116
 0.48348116 0.48348116 0.48348116 0.48348116]
rev_score of L9: [0.47700743 0.47700743 0.47700743 0.47700743 0.47700743 0.47700743
 0.47700743 0.47700743 0.47700743 0.47700743]
rev_score of L10: [0.46585784 0.46585784 0.46585784 0.46585784 0.46585784 0.46585784
 0.46585784 0.46585784 0.46585784 0.46585784]
rev_score of L11: [0.47742403 0.47742403 0.47742403 0.47742403 0.47742403 0.47742403
 0.47742403 0.47742403 0.47742403 0.47742403]
rev_score of L12: [0.48899983 0.48899983 0.48899983 0.48899983 0.48899983 0.48899983
 0.48899983 0.48899983 0.48899983 0.48899983]
rev_score of L13: [0.47499243 0.47499243 0.47499243 0.47499243 0.47499243 0.47499243
 0.47499243 0.47499243 0.47499243 0.47499243]
rev_score of L14: [0.47044889 0.47044889 0.47044889 0.47044889 0.47044889 0.47044889
 0.47044889 0.47044889 0.47044889 0.47044889]
rev_score of L15: [0.4846221 0.4846221 0.4846221 0.4846221 0.4846221 0.4846221 0.4846221
 0.4846221 0.4846221 0.4846221]
rev_score of L16: [0.46646302 0.46646302 0.46646302 0.46646302 0.46646302 0.46646302
 0.46646302 0.46646302 0.46646302 0.46646302]
rev_score of L17: [0.4666534 0.4666534 0.4666534 0.4666534 0.4666534 0.4666534 0.4666534
 0.4666534 0.4666534 0.4666534]
rev_score of L18: [0.4678331 0.4678331 0.4678331 0.4678331 0.4678331 0.4678331 0.4678331
 0.4678331 0.4678331 0.4678331]
rev_score of L19: [0.4784636 0.4784636 0.4784636 0.4784636 0.4784636 0.4784636 0.4784636
 0.4784636 0.4784636 0.4784636]
fwd_score of A0: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.10737418 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Loss: 2.2733059047510067, Acc: 0.1375
Round 30/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.43604304 -0.43604304 -0.43604304 -0.43604304 -0.43604304 -0.43604304
 -0.43604304 -0.43604304 -0.43604304 -0.43604304]
hahaha
rev_score of L1: [-0.41724519 -0.41724519 -0.41724519 -0.41724519 -0.41724519 -0.41724519
 -0.41724519 -0.41724519 -0.41724519 -0.41724519]
rev_score of L2: [0.50301149 0.50301149 0.50301149 0.50301149 0.50301149 0.50301149
 0.50301149 0.50301149 0.50301149 0.50301149]
rev_score of L3: [0.50416908 0.50416908 0.50416908 0.50416908 0.50416908 0.50416908
 0.50416908 0.50416908 0.50416908 0.50416908]
rev_score of L4: [0.49714453 0.49714453 0.49714453 0.49714453 0.49714453 0.49714453
 0.49714453 0.49714453 0.49714453 0.49714453]
rev_score of L5: [0.50490159 0.50490159 0.50490159 0.50490159 0.50490159 0.50490159
 0.50490159 0.50490159 0.50490159 0.50490159]
rev_score of L6: [0.49769774 0.49769774 0.49769774 0.49769774 0.49769774 0.49769774
 0.49769774 0.49769774 0.49769774 0.49769774]
rev_score of L7: [0.4859508 0.4859508 0.4859508 0.4859508 0.4859508 0.4859508 0.4859508
 0.4859508 0.4859508 0.4859508]
rev_score of L8: [0.50365638 0.50365638 0.50365638 0.50365638 0.50365638 0.50365638
 0.50365638 0.50365638 0.50365638 0.50365638]
rev_score of L9: [0.49783414 0.49783414 0.49783414 0.49783414 0.49783414 0.49783414
 0.49783414 0.49783414 0.49783414 0.49783414]
rev_score of L10: [0.50580654 0.50580654 0.50580654 0.50580654 0.50580654 0.50580654
 0.50580654 0.50580654 0.50580654 0.50580654]
rev_score of L11: [0.50079303 0.50079303 0.50079303 0.50079303 0.50079303 0.50079303
 0.50079303 0.50079303 0.50079303 0.50079303]
rev_score of L12: [0.50869681 0.50869681 0.50869681 0.50869681 0.50869681 0.50869681
 0.50869681 0.50869681 0.50869681 0.50869681]
rev_score of L13: [0.51451125 0.51451125 0.51451125 0.51451125 0.51451125 0.51451125
 0.51451125 0.51451125 0.51451125 0.51451125]
rev_score of L14: [0.49032171 0.49032171 0.49032171 0.49032171 0.49032171 0.49032171
 0.49032171 0.49032171 0.49032171 0.49032171]
rev_score of L15: [0.501584 0.501584 0.501584 0.501584 0.501584 0.501584 0.501584 0.501584
 0.501584 0.501584]
rev_score of L16: [0.49789493 0.49789493 0.49789493 0.49789493 0.49789493 0.49789493
 0.49789493 0.49789493 0.49789493 0.49789493]
rev_score of L17: [0.50854255 0.50854255 0.50854255 0.50854255 0.50854255 0.50854255
 0.50854255 0.50854255 0.50854255 0.50854255]
rev_score of L18: [0.49455636 0.49455636 0.49455636 0.49455636 0.49455636 0.49455636
 0.49455636 0.49455636 0.49455636 0.49455636]
rev_score of L19: [0.50082436 0.50082436 0.50082436 0.50082436 0.50082436 0.50082436
 0.50082436 0.50082436 0.50082436 0.50082436]
fwd_score of A0: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.08589935 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Loss: 2.040931418300056, Acc: 0.2606
Round 31/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.41338349 -0.41338349 -0.41338349 -0.41338349 -0.41338349 -0.41338349
 -0.41338349 -0.41338349 -0.41338349 -0.41338349]
hahaha
rev_score of L1: [-0.40637964 -0.40637964 -0.40637964 -0.40637964 -0.40637964 -0.40637964
 -0.40637964 -0.40637964 -0.40637964 -0.40637964]
rev_score of L2: [0.47964418 0.47964418 0.47964418 0.47964418 0.47964418 0.47964418
 0.47964418 0.47964418 0.47964418 0.47964418]
rev_score of L3: [0.4687622 0.4687622 0.4687622 0.4687622 0.4687622 0.4687622 0.4687622
 0.4687622 0.4687622 0.4687622]
rev_score of L4: [0.47137094 0.47137094 0.47137094 0.47137094 0.47137094 0.47137094
 0.47137094 0.47137094 0.47137094 0.47137094]
rev_score of L5: [0.47109775 0.47109775 0.47109775 0.47109775 0.47109775 0.47109775
 0.47109775 0.47109775 0.47109775 0.47109775]
rev_score of L6: [0.45633778 0.45633778 0.45633778 0.45633778 0.45633778 0.45633778
 0.45633778 0.45633778 0.45633778 0.45633778]
rev_score of L7: [0.47056648 0.47056648 0.47056648 0.47056648 0.47056648 0.47056648
 0.47056648 0.47056648 0.47056648 0.47056648]
rev_score of L8: [0.48155485 0.48155485 0.48155485 0.48155485 0.48155485 0.48155485
 0.48155485 0.48155485 0.48155485 0.48155485]
rev_score of L9: [0.4837342 0.4837342 0.4837342 0.4837342 0.4837342 0.4837342 0.4837342
 0.4837342 0.4837342 0.4837342]
rev_score of L10: [0.48161898 0.48161898 0.48161898 0.48161898 0.48161898 0.48161898
 0.48161898 0.48161898 0.48161898 0.48161898]
rev_score of L11: [0.48247243 0.48247243 0.48247243 0.48247243 0.48247243 0.48247243
 0.48247243 0.48247243 0.48247243 0.48247243]
rev_score of L12: [0.48713183 0.48713183 0.48713183 0.48713183 0.48713183 0.48713183
 0.48713183 0.48713183 0.48713183 0.48713183]
rev_score of L13: [0.47861666 0.47861666 0.47861666 0.47861666 0.47861666 0.47861666
 0.47861666 0.47861666 0.47861666 0.47861666]
rev_score of L14: [0.47954267 0.47954267 0.47954267 0.47954267 0.47954267 0.47954267
 0.47954267 0.47954267 0.47954267 0.47954267]
rev_score of L15: [0.48965973 0.48965973 0.48965973 0.48965973 0.48965973 0.48965973
 0.48965973 0.48965973 0.48965973 0.48965973]
rev_score of L16: [0.47473964 0.47473964 0.47473964 0.47473964 0.47473964 0.47473964
 0.47473964 0.47473964 0.47473964 0.47473964]
rev_score of L17: [0.4798472 0.4798472 0.4798472 0.4798472 0.4798472 0.4798472 0.4798472
 0.4798472 0.4798472 0.4798472]
rev_score of L18: [0.46588238 0.46588238 0.46588238 0.46588238 0.46588238 0.46588238
 0.46588238 0.46588238 0.46588238 0.46588238]
rev_score of L19: [0.47507285 0.47507285 0.47507285 0.47507285 0.47507285 0.47507285
 0.47507285 0.47507285 0.47507285 0.47507285]
fwd_score of A0: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.06871948 0.03518437 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Loss: 2.1956307926117042, Acc: 0.138
Round 32/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4153693 -0.4153693 -0.4153693 -0.4153693 -0.4153693 -0.4153693
 -0.4153693 -0.4153693 -0.4153693 -0.4153693]
hahaha
rev_score of L1: [-0.42932646 -0.42932646 -0.42932646 -0.42932646 -0.42932646 -0.42932646
 -0.42932646 -0.42932646 -0.42932646 -0.42932646]
rev_score of L2: [0.4928732 0.4928732 0.4928732 0.4928732 0.4928732 0.4928732 0.4928732
 0.4928732 0.4928732 0.4928732]
rev_score of L3: [0.48804366 0.48804366 0.48804366 0.48804366 0.48804366 0.48804366
 0.48804366 0.48804366 0.48804366 0.48804366]
rev_score of L4: [0.49324434 0.49324434 0.49324434 0.49324434 0.49324434 0.49324434
 0.49324434 0.49324434 0.49324434 0.49324434]
rev_score of L5: [0.46366186 0.46366186 0.46366186 0.46366186 0.46366186 0.46366186
 0.46366186 0.46366186 0.46366186 0.46366186]
rev_score of L6: [0.487853 0.487853 0.487853 0.487853 0.487853 0.487853 0.487853 0.487853
 0.487853 0.487853]
rev_score of L7: [0.48974712 0.48974712 0.48974712 0.48974712 0.48974712 0.48974712
 0.48974712 0.48974712 0.48974712 0.48974712]
rev_score of L8: [0.4802279 0.4802279 0.4802279 0.4802279 0.4802279 0.4802279 0.4802279
 0.4802279 0.4802279 0.4802279]
rev_score of L9: [0.47931575 0.47931575 0.47931575 0.47931575 0.47931575 0.47931575
 0.47931575 0.47931575 0.47931575 0.47931575]
rev_score of L10: [0.48423845 0.48423845 0.48423845 0.48423845 0.48423845 0.48423845
 0.48423845 0.48423845 0.48423845 0.48423845]
rev_score of L11: [0.48626147 0.48626147 0.48626147 0.48626147 0.48626147 0.48626147
 0.48626147 0.48626147 0.48626147 0.48626147]
rev_score of L12: [0.48530831 0.48530831 0.48530831 0.48530831 0.48530831 0.48530831
 0.48530831 0.48530831 0.48530831 0.48530831]
rev_score of L13: [0.4907485 0.4907485 0.4907485 0.4907485 0.4907485 0.4907485 0.4907485
 0.4907485 0.4907485 0.4907485]
rev_score of L14: [0.49040754 0.49040754 0.49040754 0.49040754 0.49040754 0.49040754
 0.49040754 0.49040754 0.49040754 0.49040754]
rev_score of L15: [0.47256621 0.47256621 0.47256621 0.47256621 0.47256621 0.47256621
 0.47256621 0.47256621 0.47256621 0.47256621]
rev_score of L16: [0.49791082 0.49791082 0.49791082 0.49791082 0.49791082 0.49791082
 0.49791082 0.49791082 0.49791082 0.49791082]
rev_score of L17: [0.48924911 0.48924911 0.48924911 0.48924911 0.48924911 0.48924911
 0.48924911 0.48924911 0.48924911 0.48924911]
rev_score of L18: [0.49173016 0.49173016 0.49173016 0.49173016 0.49173016 0.49173016
 0.49173016 0.49173016 0.49173016 0.49173016]
rev_score of L19: [0.48326892 0.48326892 0.48326892 0.48326892 0.48326892 0.48326892
 0.48326892 0.48326892 0.48326892 0.48326892]
fwd_score of A0: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.06871948 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Loss: 2.1400575835864766, Acc: 0.1893
Round 33/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.47576554 -0.47576554 -0.47576554 -0.47576554 -0.47576554 -0.47576554
 -0.47576554 -0.47576554 -0.47576554 -0.47576554]
hahaha
rev_score of L1: [-0.47186173 -0.47186173 -0.47186173 -0.47186173 -0.47186173 -0.47186173
 -0.47186173 -0.47186173 -0.47186173 -0.47186173]
rev_score of L2: [0.5217962 0.5217962 0.5217962 0.5217962 0.5217962 0.5217962 0.5217962
 0.5217962 0.5217962 0.5217962]
rev_score of L3: [0.52387643 0.52387643 0.52387643 0.52387643 0.52387643 0.52387643
 0.52387643 0.52387643 0.52387643 0.52387643]
rev_score of L4: [0.51709497 0.51709497 0.51709497 0.51709497 0.51709497 0.51709497
 0.51709497 0.51709497 0.51709497 0.51709497]
rev_score of L5: [0.51034067 0.51034067 0.51034067 0.51034067 0.51034067 0.51034067
 0.51034067 0.51034067 0.51034067 0.51034067]
rev_score of L6: [0.51497732 0.51497732 0.51497732 0.51497732 0.51497732 0.51497732
 0.51497732 0.51497732 0.51497732 0.51497732]
rev_score of L7: [0.52331518 0.52331518 0.52331518 0.52331518 0.52331518 0.52331518
 0.52331518 0.52331518 0.52331518 0.52331518]
rev_score of L8: [0.51873288 0.51873288 0.51873288 0.51873288 0.51873288 0.51873288
 0.51873288 0.51873288 0.51873288 0.51873288]
rev_score of L9: [0.50745895 0.50745895 0.50745895 0.50745895 0.50745895 0.50745895
 0.50745895 0.50745895 0.50745895 0.50745895]
rev_score of L10: [0.52122692 0.52122692 0.52122692 0.52122692 0.52122692 0.52122692
 0.52122692 0.52122692 0.52122692 0.52122692]
rev_score of L11: [0.51498972 0.51498972 0.51498972 0.51498972 0.51498972 0.51498972
 0.51498972 0.51498972 0.51498972 0.51498972]
rev_score of L12: [0.51931128 0.51931128 0.51931128 0.51931128 0.51931128 0.51931128
 0.51931128 0.51931128 0.51931128 0.51931128]
rev_score of L13: [0.50785463 0.50785463 0.50785463 0.50785463 0.50785463 0.50785463
 0.50785463 0.50785463 0.50785463 0.50785463]
rev_score of L14: [0.5130444 0.5130444 0.5130444 0.5130444 0.5130444 0.5130444 0.5130444
 0.5130444 0.5130444 0.5130444]
rev_score of L15: [0.51160004 0.51160004 0.51160004 0.51160004 0.51160004 0.51160004
 0.51160004 0.51160004 0.51160004 0.51160004]
rev_score of L16: [0.52319892 0.52319892 0.52319892 0.52319892 0.52319892 0.52319892
 0.52319892 0.52319892 0.52319892 0.52319892]
rev_score of L17: [0.50657056 0.50657056 0.50657056 0.50657056 0.50657056 0.50657056
 0.50657056 0.50657056 0.50657056 0.50657056]
rev_score of L18: [0.51922613 0.51922613 0.51922613 0.51922613 0.51922613 0.51922613
 0.51922613 0.51922613 0.51922613 0.51922613]
rev_score of L19: [0.50436407 0.50436407 0.50436407 0.50436407 0.50436407 0.50436407
 0.50436407 0.50436407 0.50436407 0.50436407]
fwd_score of A0: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.05497558 0.0281475  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Loss: 2.0708244875216257, Acc: 0.2452
Round 34/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4483728 -0.4483728 -0.4483728 -0.4483728 -0.4483728 -0.4483728
 -0.4483728 -0.4483728 -0.4483728 -0.4483728]
hahaha
rev_score of L1: [-0.45416827 -0.45416827 -0.45416827 -0.45416827 -0.45416827 -0.45416827
 -0.45416827 -0.45416827 -0.45416827 -0.45416827]
rev_score of L2: [0.51655381 0.51655381 0.51655381 0.51655381 0.51655381 0.51655381
 0.51655381 0.51655381 0.51655381 0.51655381]
rev_score of L3: [0.50428361 0.50428361 0.50428361 0.50428361 0.50428361 0.50428361
 0.50428361 0.50428361 0.50428361 0.50428361]
rev_score of L4: [0.51092627 0.51092627 0.51092627 0.51092627 0.51092627 0.51092627
 0.51092627 0.51092627 0.51092627 0.51092627]
rev_score of L5: [0.49305111 0.49305111 0.49305111 0.49305111 0.49305111 0.49305111
 0.49305111 0.49305111 0.49305111 0.49305111]
rev_score of L6: [0.50256518 0.50256518 0.50256518 0.50256518 0.50256518 0.50256518
 0.50256518 0.50256518 0.50256518 0.50256518]
rev_score of L7: [0.49957024 0.49957024 0.49957024 0.49957024 0.49957024 0.49957024
 0.49957024 0.49957024 0.49957024 0.49957024]
rev_score of L8: [0.49024042 0.49024042 0.49024042 0.49024042 0.49024042 0.49024042
 0.49024042 0.49024042 0.49024042 0.49024042]
rev_score of L9: [0.50223289 0.50223289 0.50223289 0.50223289 0.50223289 0.50223289
 0.50223289 0.50223289 0.50223289 0.50223289]
rev_score of L10: [0.50317276 0.50317276 0.50317276 0.50317276 0.50317276 0.50317276
 0.50317276 0.50317276 0.50317276 0.50317276]
rev_score of L11: [0.49384855 0.49384855 0.49384855 0.49384855 0.49384855 0.49384855
 0.49384855 0.49384855 0.49384855 0.49384855]
rev_score of L12: [0.50202948 0.50202948 0.50202948 0.50202948 0.50202948 0.50202948
 0.50202948 0.50202948 0.50202948 0.50202948]
rev_score of L13: [0.49508901 0.49508901 0.49508901 0.49508901 0.49508901 0.49508901
 0.49508901 0.49508901 0.49508901 0.49508901]
rev_score of L14: [0.4886402 0.4886402 0.4886402 0.4886402 0.4886402 0.4886402 0.4886402
 0.4886402 0.4886402 0.4886402]
rev_score of L15: [0.49728707 0.49728707 0.49728707 0.49728707 0.49728707 0.49728707
 0.49728707 0.49728707 0.49728707 0.49728707]
rev_score of L16: [0.48966191 0.48966191 0.48966191 0.48966191 0.48966191 0.48966191
 0.48966191 0.48966191 0.48966191 0.48966191]
rev_score of L17: [0.49832961 0.49832961 0.49832961 0.49832961 0.49832961 0.49832961
 0.49832961 0.49832961 0.49832961 0.49832961]
rev_score of L18: [0.50280285 0.50280285 0.50280285 0.50280285 0.50280285 0.50280285
 0.50280285 0.50280285 0.50280285 0.50280285]
rev_score of L19: [0.49371908 0.49371908 0.49371908 0.49371908 0.49371908 0.49371908
 0.49371908 0.49371908 0.49371908 0.49371908]
fwd_score of A0: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.05497558 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Loss: 2.1000508797435335, Acc: 0.2214
Round 35/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4543258 -0.4543258 -0.4543258 -0.4543258 -0.4543258 -0.4543258
 -0.4543258 -0.4543258 -0.4543258 -0.4543258]
hahaha
rev_score of L1: [-0.44984129 -0.44984129 -0.44984129 -0.44984129 -0.44984129 -0.44984129
 -0.44984129 -0.44984129 -0.44984129 -0.44984129]
rev_score of L2: [0.50372182 0.50372182 0.50372182 0.50372182 0.50372182 0.50372182
 0.50372182 0.50372182 0.50372182 0.50372182]
rev_score of L3: [0.50254417 0.50254417 0.50254417 0.50254417 0.50254417 0.50254417
 0.50254417 0.50254417 0.50254417 0.50254417]
rev_score of L4: [0.50633894 0.50633894 0.50633894 0.50633894 0.50633894 0.50633894
 0.50633894 0.50633894 0.50633894 0.50633894]
rev_score of L5: [0.50008431 0.50008431 0.50008431 0.50008431 0.50008431 0.50008431
 0.50008431 0.50008431 0.50008431 0.50008431]
rev_score of L6: [0.5016388 0.5016388 0.5016388 0.5016388 0.5016388 0.5016388 0.5016388
 0.5016388 0.5016388 0.5016388]
rev_score of L7: [0.50700797 0.50700797 0.50700797 0.50700797 0.50700797 0.50700797
 0.50700797 0.50700797 0.50700797 0.50700797]
rev_score of L8: [0.50441365 0.50441365 0.50441365 0.50441365 0.50441365 0.50441365
 0.50441365 0.50441365 0.50441365 0.50441365]
rev_score of L9: [0.49250028 0.49250028 0.49250028 0.49250028 0.49250028 0.49250028
 0.49250028 0.49250028 0.49250028 0.49250028]
rev_score of L10: [0.50693851 0.50693851 0.50693851 0.50693851 0.50693851 0.50693851
 0.50693851 0.50693851 0.50693851 0.50693851]
rev_score of L11: [0.50708277 0.50708277 0.50708277 0.50708277 0.50708277 0.50708277
 0.50708277 0.50708277 0.50708277 0.50708277]
rev_score of L12: [0.5035805 0.5035805 0.5035805 0.5035805 0.5035805 0.5035805 0.5035805
 0.5035805 0.5035805 0.5035805]
rev_score of L13: [0.50733485 0.50733485 0.50733485 0.50733485 0.50733485 0.50733485
 0.50733485 0.50733485 0.50733485 0.50733485]
rev_score of L14: [0.50405348 0.50405348 0.50405348 0.50405348 0.50405348 0.50405348
 0.50405348 0.50405348 0.50405348 0.50405348]
rev_score of L15: [0.50365569 0.50365569 0.50365569 0.50365569 0.50365569 0.50365569
 0.50365569 0.50365569 0.50365569 0.50365569]
rev_score of L16: [0.49231107 0.49231107 0.49231107 0.49231107 0.49231107 0.49231107
 0.49231107 0.49231107 0.49231107 0.49231107]
rev_score of L17: [0.49565511 0.49565511 0.49565511 0.49565511 0.49565511 0.49565511
 0.49565511 0.49565511 0.49565511 0.49565511]
rev_score of L18: [0.51483432 0.51483432 0.51483432 0.51483432 0.51483432 0.51483432
 0.51483432 0.51483432 0.51483432 0.51483432]
rev_score of L19: [0.50433789 0.50433789 0.50433789 0.50433789 0.50433789 0.50433789
 0.50433789 0.50433789 0.50433789 0.50433789]
fwd_score of A0: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.04398047 0.022518   1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Loss: 2.2662160918354606, Acc: 0.1419
Round 36/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.42866442 -0.42866442 -0.42866442 -0.42866442 -0.42866442 -0.42866442
 -0.42866442 -0.42866442 -0.42866442 -0.42866442]
hahaha
rev_score of L1: [-0.44381498 -0.44381498 -0.44381498 -0.44381498 -0.44381498 -0.44381498
 -0.44381498 -0.44381498 -0.44381498 -0.44381498]
rev_score of L2: [0.50470003 0.50470003 0.50470003 0.50470003 0.50470003 0.50470003
 0.50470003 0.50470003 0.50470003 0.50470003]
rev_score of L3: [0.49649524 0.49649524 0.49649524 0.49649524 0.49649524 0.49649524
 0.49649524 0.49649524 0.49649524 0.49649524]
rev_score of L4: [0.48659418 0.48659418 0.48659418 0.48659418 0.48659418 0.48659418
 0.48659418 0.48659418 0.48659418 0.48659418]
rev_score of L5: [0.49864012 0.49864012 0.49864012 0.49864012 0.49864012 0.49864012
 0.49864012 0.49864012 0.49864012 0.49864012]
rev_score of L6: [0.4983432 0.4983432 0.4983432 0.4983432 0.4983432 0.4983432 0.4983432
 0.4983432 0.4983432 0.4983432]
rev_score of L7: [0.49263722 0.49263722 0.49263722 0.49263722 0.49263722 0.49263722
 0.49263722 0.49263722 0.49263722 0.49263722]
rev_score of L8: [0.49451593 0.49451593 0.49451593 0.49451593 0.49451593 0.49451593
 0.49451593 0.49451593 0.49451593 0.49451593]
rev_score of L9: [0.48810949 0.48810949 0.48810949 0.48810949 0.48810949 0.48810949
 0.48810949 0.48810949 0.48810949 0.48810949]
rev_score of L10: [0.49854302 0.49854302 0.49854302 0.49854302 0.49854302 0.49854302
 0.49854302 0.49854302 0.49854302 0.49854302]
rev_score of L11: [0.49304717 0.49304717 0.49304717 0.49304717 0.49304717 0.49304717
 0.49304717 0.49304717 0.49304717 0.49304717]
rev_score of L12: [0.48897199 0.48897199 0.48897199 0.48897199 0.48897199 0.48897199
 0.48897199 0.48897199 0.48897199 0.48897199]
rev_score of L13: [0.50976385 0.50976385 0.50976385 0.50976385 0.50976385 0.50976385
 0.50976385 0.50976385 0.50976385 0.50976385]
rev_score of L14: [0.49488573 0.49488573 0.49488573 0.49488573 0.49488573 0.49488573
 0.49488573 0.49488573 0.49488573 0.49488573]
rev_score of L15: [0.5029304 0.5029304 0.5029304 0.5029304 0.5029304 0.5029304 0.5029304
 0.5029304 0.5029304 0.5029304]
rev_score of L16: [0.47950458 0.47950458 0.47950458 0.47950458 0.47950458 0.47950458
 0.47950458 0.47950458 0.47950458 0.47950458]
rev_score of L17: [0.48888617 0.48888617 0.48888617 0.48888617 0.48888617 0.48888617
 0.48888617 0.48888617 0.48888617 0.48888617]
rev_score of L18: [0.49410823 0.49410823 0.49410823 0.49410823 0.49410823 0.49410823
 0.49410823 0.49410823 0.49410823 0.49410823]
rev_score of L19: [0.50438648 0.50438648 0.50438648 0.50438648 0.50438648 0.50438648
 0.50438648 0.50438648 0.50438648 0.50438648]
fwd_score of A0: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.04398047 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Loss: 2.0992821291231882, Acc: 0.2296
Round 37/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4627303 -0.4627303 -0.4627303 -0.4627303 -0.4627303 -0.4627303
 -0.4627303 -0.4627303 -0.4627303 -0.4627303]
hahaha
rev_score of L1: [-0.45570027 -0.45570027 -0.45570027 -0.45570027 -0.45570027 -0.45570027
 -0.45570027 -0.45570027 -0.45570027 -0.45570027]
rev_score of L2: [0.51486494 0.51486494 0.51486494 0.51486494 0.51486494 0.51486494
 0.51486494 0.51486494 0.51486494 0.51486494]
rev_score of L3: [0.52246813 0.52246813 0.52246813 0.52246813 0.52246813 0.52246813
 0.52246813 0.52246813 0.52246813 0.52246813]
rev_score of L4: [0.52122522 0.52122522 0.52122522 0.52122522 0.52122522 0.52122522
 0.52122522 0.52122522 0.52122522 0.52122522]
rev_score of L5: [0.5238784 0.5238784 0.5238784 0.5238784 0.5238784 0.5238784 0.5238784
 0.5238784 0.5238784 0.5238784]
rev_score of L6: [0.52606591 0.52606591 0.52606591 0.52606591 0.52606591 0.52606591
 0.52606591 0.52606591 0.52606591 0.52606591]
rev_score of L7: [0.51663595 0.51663595 0.51663595 0.51663595 0.51663595 0.51663595
 0.51663595 0.51663595 0.51663595 0.51663595]
rev_score of L8: [0.51321665 0.51321665 0.51321665 0.51321665 0.51321665 0.51321665
 0.51321665 0.51321665 0.51321665 0.51321665]
rev_score of L9: [0.52208621 0.52208621 0.52208621 0.52208621 0.52208621 0.52208621
 0.52208621 0.52208621 0.52208621 0.52208621]
rev_score of L10: [0.51848844 0.51848844 0.51848844 0.51848844 0.51848844 0.51848844
 0.51848844 0.51848844 0.51848844 0.51848844]
rev_score of L11: [0.52226102 0.52226102 0.52226102 0.52226102 0.52226102 0.52226102
 0.52226102 0.52226102 0.52226102 0.52226102]
rev_score of L12: [0.52241952 0.52241952 0.52241952 0.52241952 0.52241952 0.52241952
 0.52241952 0.52241952 0.52241952 0.52241952]
rev_score of L13: [0.51977784 0.51977784 0.51977784 0.51977784 0.51977784 0.51977784
 0.51977784 0.51977784 0.51977784 0.51977784]
rev_score of L14: [0.51274601 0.51274601 0.51274601 0.51274601 0.51274601 0.51274601
 0.51274601 0.51274601 0.51274601 0.51274601]
rev_score of L15: [0.52625626 0.52625626 0.52625626 0.52625626 0.52625626 0.52625626
 0.52625626 0.52625626 0.52625626 0.52625626]
rev_score of L16: [0.51676303 0.51676303 0.51676303 0.51676303 0.51676303 0.51676303
 0.51676303 0.51676303 0.51676303 0.51676303]
rev_score of L17: [0.52597486 0.52597486 0.52597486 0.52597486 0.52597486 0.52597486
 0.52597486 0.52597486 0.52597486 0.52597486]
rev_score of L18: [0.51989658 0.51989658 0.51989658 0.51989658 0.51989658 0.51989658
 0.51989658 0.51989658 0.51989658 0.51989658]
rev_score of L19: [0.52058416 0.52058416 0.52058416 0.52058416 0.52058416 0.52058416
 0.52058416 0.52058416 0.52058416 0.52058416]
fwd_score of A0: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.03518437 0.0180144  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Loss: 2.0312676224083948, Acc: 0.2741
Round 38/40 its me
Learner 0 finished training
hahaha
Learner 1 finished training
hahaha
Learner 2 finished training
Learner 3 finished training
Learner 4 finished training
Learner 5 finished training
Learner 6 finished training
Learner 7 finished training
Learner 8 finished training
Learner 9 finished training
Learner 10 finished training
Learner 11 finished training
Learner 12 finished training
Learner 13 finished training
Learner 14 finished training
Learner 15 finished training
Learner 16 finished training
Learner 17 finished training
Learner 18 finished training
Learner 19 finished training
hahaha
rev_score of L0: [-0.4371644 -0.4371644 -0.4371644 -0.4371644 -0.4371644 -0.4371644
 -0.4371644 -0.4371644 -0.4371644 -0.4371644]
hahaha
rev_score of L1: [-0.4389773 -0.4389773 -0.4389773 -0.4389773 -0.4389773 -0.4389773
 -0.4389773 -0.4389773 -0.4389773 -0.4389773]
rev_score of L2: [0.50760879 0.50760879 0.50760879 0.50760879 0.50760879 0.50760879
 0.50760879 0.50760879 0.50760879 0.50760879]
rev_score of L3: [0.50602353 0.50602353 0.50602353 0.50602353 0.50602353 0.50602353
 0.50602353 0.50602353 0.50602353 0.50602353]
rev_score of L4: [0.49781902 0.49781902 0.49781902 0.49781902 0.49781902 0.49781902
 0.49781902 0.49781902 0.49781902 0.49781902]
rev_score of L5: [0.49815788 0.49815788 0.49815788 0.49815788 0.49815788 0.49815788
 0.49815788 0.49815788 0.49815788 0.49815788]
rev_score of L6: [0.49654525 0.49654525 0.49654525 0.49654525 0.49654525 0.49654525
 0.49654525 0.49654525 0.49654525 0.49654525]
rev_score of L7: [0.48918269 0.48918269 0.48918269 0.48918269 0.48918269 0.48918269
 0.48918269 0.48918269 0.48918269 0.48918269]
rev_score of L8: [0.50118786 0.50118786 0.50118786 0.50118786 0.50118786 0.50118786
 0.50118786 0.50118786 0.50118786 0.50118786]
rev_score of L9: [0.49962083 0.49962083 0.49962083 0.49962083 0.49962083 0.49962083
 0.49962083 0.49962083 0.49962083 0.49962083]
rev_score of L10: [0.50832364 0.50832364 0.50832364 0.50832364 0.50832364 0.50832364
 0.50832364 0.50832364 0.50832364 0.50832364]
rev_score of L11: [0.5134964 0.5134964 0.5134964 0.5134964 0.5134964 0.5134964 0.5134964
 0.5134964 0.5134964 0.5134964]
rev_score of L12: [0.50633821 0.50633821 0.50633821 0.50633821 0.50633821 0.50633821
 0.50633821 0.50633821 0.50633821 0.50633821]
rev_score of L13: [0.49531251 0.49531251 0.49531251 0.49531251 0.49531251 0.49531251
 0.49531251 0.49531251 0.49531251 0.49531251]
rev_score of L14: [0.50124652 0.50124652 0.50124652 0.50124652 0.50124652 0.50124652
 0.50124652 0.50124652 0.50124652 0.50124652]
rev_score of L15: [0.50556179 0.50556179 0.50556179 0.50556179 0.50556179 0.50556179
 0.50556179 0.50556179 0.50556179 0.50556179]
rev_score of L16: [0.50365752 0.50365752 0.50365752 0.50365752 0.50365752 0.50365752
 0.50365752 0.50365752 0.50365752 0.50365752]
rev_score of L17: [0.51202128 0.51202128 0.51202128 0.51202128 0.51202128 0.51202128
 0.51202128 0.51202128 0.51202128 0.51202128]
rev_score of L18: [0.49465815 0.49465815 0.49465815 0.49465815 0.49465815 0.49465815
 0.49465815 0.49465815 0.49465815 0.49465815]
rev_score of L19: [0.49937368 0.49937368 0.49937368 0.49937368 0.49937368 0.49937368
 0.49937368 0.49937368 0.49937368 0.49937368]
fwd_score of A0: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A1: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A2: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A3: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A4: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A5: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A6: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A7: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A8: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
fwd_score of A9: [0.03518437 0.01441152 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
Loss: 2.150446304498008, Acc: 0.1995
